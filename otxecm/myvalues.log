NAME: xecm-release
LAST DEPLOYED: Fri Aug 22 10:25:59 2025
NAMESPACE: default
STATUS: pending-install
REVISION: 1
TEST SUITE: None
USER-SUPPLIED VALUES:
global:
  database:
    admin: postgres
    hostname: 192.168.100.216
    ivName: otiv
    password: Opentext1!
    port: 5432
  imagePullPolicy: IfNotPresent
  imagePullSecret: regcred
  imageSource: registry.opentext.com
  ingressAnnotations:
    kubernetes.io/ingress.allow-http: false
    nginx.ingress.kubernetes.io/affinity: cookie
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
    nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
  ingressClass: nginx
  ingressDomainName: myubuntu6.hv
  ingressEnabled: true
  ingressSSLSecret: xecm-secret
  masterPassword: Opentext1!
  otac:
    enabled: true
  otacPublicUrl: https://otac.myubuntu6.hv
  otacc:
    enabled: false
  otcsPublicUrl: https://otcs.myubuntu6.hv
  otds:
    enabled: true
  otdsPublicUrl: https://otds.myubuntu6.hv
  otiv:
    enabled: true
  otpd:
    enabled: false
  otpdPublicUrl: https://otpd.myubuntu6.hv
  resourceRequirements: false
  serviceAccountName: otxecm-sa
  storageClassName: microk8s-hostpath
  storageClassNameNFS: microk8s-hostpath
  timeZone: Asia/Seoul
otcs:
  config:
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    database:
      adminUsername: postgres
      name: cs
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    deployBusinessScenarios: true
    extensions:
      enabled: true
      includeManifestInitContainer: false
    otds:
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    useExtendedECMLicese: false
  containerLogLevel: DEBUG
  contentServerBackendSearch:
    replicas: 1
  contentServerFrontend:
    replicas: 1
  loadAdminSettings:
    enabled: false
  loadLicense:
    enabled: false
    filename: otxecmLicense.lic
  objectimporter:
    enabled: true
  passwords:
    database:
      adminPassword: Opentext1!
    scenarioOwnerPassword: Opentext1!
otds:
  otdsws:
    cryptKey: Z2hkN2hyNDBkbWNGcVQ0TA==
    otdsdb:
      automaticDatabaseCreation:
        dbName: otdsdb
        enabled: false
      password: Opentext1!
      url: jdbc:postgresql://192.168.100.216:5432/otdsdb
      username: otdsuser
otiv:
  amqp:
    rabbitmq:
      password: Opentext1!
otpd:
  database:
    hostname: 192.168.100.216
  loadLicense: false
  otpdLicense: otpdLicense.lic
  technicalUserPassword: Opentext1!

COMPUTED VALUES:
global:
  amqp:
    password: null
  database:
    admin: postgres
    adminDatabase: postgres
    adminUsername: postgres
    hostname: 192.168.100.216
    ivName: otiv
    ivUsername: otiv
    password: Opentext1!
    port: 5432
    ssl: false
  existingLicenseSecret: null
  existingSecret: otxecm-default-secrets
  imagePullPolicy: IfNotPresent
  imagePullSecret: regcred
  imageSource: registry.opentext.com
  imageSourcePublic: docker.io
  ingressAnnotations:
    alb.ingress.kubernetes.io/configuration-snippet: |
      if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
    alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
    alb.ingress.kubernetes.io/target-type: ip
    kubernetes.io/ingress.allow-http: false
    nginx.ingress.kubernetes.io/affinity: cookie
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
    nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
      nofollow";
  ingressAnnotationsCustom: {}
  ingressClass: nginx
  ingressDomainName: myubuntu6.hv
  ingressEnabled: true
  ingressIncludeNamespace: false
  ingressOtivAsset: null
  ingressOtivHighlight: null
  ingressOtivMarkup: null
  ingressOtivPublication: null
  ingressOtivViewer: null
  ingressSSLSecret: xecm-secret
  masterPassword: Opentext1!
  otac:
    enabled: true
  otacPublicUrl: https://otac.myubuntu6.hv
  otacc:
    enabled: false
  otaccPublicUrl: https://otacc.example.com
  otcs:
    enabled: true
  otcsPublicUrl: https://otcs.myubuntu6.hv
  otds:
    enabled: true
  otdsInCluster: true
  otdsPrivateUrl: null
  otdsPublicUrl: https://otds.myubuntu6.hv
  otdsServiceName: otds
  otdsUseReleaseName: false
  otiv:
    enabled: true
  otpd:
    enabled: false
  otpdPublicUrl: https://otpd.myubuntu6.hv
  otxecmctrl:
    enabled: true
  passwords:
    database:
      adminPassword: null
      ivPassword: null
  pdb:
    enabled: true
  priorityClasses:
    enabled: true
  resourceRequirements: false
  secretlink:
    enabled: false
    image:
      name: secretlink
      tag: 25.3.0
    loglevel: INFO
    vault: {}
  serviceAccountName: otxecm-sa
  serviceType: NodePort
  storageClassName: microk8s-hostpath
  storageClassNameNFS: microk8s-hostpath
  timeZone: Asia/Seoul
  trustedSourceOrigins: http://otcs-frontend
  trustedSourceOriginsAnonymous: null
otac:
  GOOGLE_APPLICATION_CREDENTIALS: /opt/opentext/archive_center/ac_config/gcp.json
  SHARED_ADDRESS_SPACE_NAT: false
  acConfigDir: /opt/opentext/archive_center/ac_config
  acPort: 4034
  archiveName: A1
  config:
    storageDevices:
      azure:
        archive2Name: A4
        enable: false
        host: https://blob.core.windows.net:443
        name: AZURE
        volumeName: volazure1
      gcs:
        archive2Name: A2
        bucketAddressStyle: VIRTUAL_HOST_STYLE
        enable: false
        name: GCP
        retentionmode: {}
        serviceAccountEnabled: false
        serviceAccountJSONFileName: gcs_serviceaccount.json
        serviceAddress: storage.googleapis.com
        volumeName: volgcs1
      s3:
        archive2Name: A3
        bucketAddressStyle: VIRTUAL_HOST_STYLE
        enable: false
        name: S3
        retentionmode: {}
        serviceAddress: s3.amazonaws.com
        userolebasedauth: false
        volumeName: vols31
  database:
    customSSLCertificate: global-bundle.pem
    executeSchema: true
    name: ac
    oracle:
      loadTnsnames:
        enabled: true
        filename: tnsnames.ora
      serviceName: ac
      tnsnamesConnectionAlias: ac
      ts_data: ac_data
      ts_index: ac_index
    postgres:
      ts_default: pg_default
    type: postgres
    username: ac
  encryption:
    enabled: false
    encKeyCacheTimeoutVal: -1
    keyStoreExportFolderVal: /opt/opentext/archive_center/ac_config/keystore
    otkm:
      caCertFileNameVal: otkm-root-ca.cer
      certCAPathVal: /opt/opentext/archive_center/ac_config/certs
      certPinningEnabledVal: false
      clientIdVal: key_mediator
      enabled: false
  forceRestart: false
  fsGroup: 1000
  global:
    amqp:
      password: null
    database:
      admin: postgres
      adminDatabase: postgres
      adminUsername: postgres
      hostname: 192.168.100.216
      ivName: otiv
      ivUsername: otiv
      password: Opentext1!
      port: 5432
      ssl: false
    existingLicenseSecret: null
    existingSecret: otxecm-default-secrets
    imagePullPolicy: IfNotPresent
    imagePullSecret: regcred
    imageSource: registry.opentext.com
    imageSourcePublic: docker.io
    ingressAnnotations:
      alb.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
      alb.ingress.kubernetes.io/target-type: ip
      kubernetes.io/ingress.allow-http: false
      nginx.ingress.kubernetes.io/affinity: cookie
      nginx.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
      nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
        nofollow";
    ingressAnnotationsCustom: {}
    ingressClass: nginx
    ingressDomainName: myubuntu6.hv
    ingressEnabled: true
    ingressIncludeNamespace: false
    ingressOtivAsset: null
    ingressOtivHighlight: null
    ingressOtivMarkup: null
    ingressOtivPublication: null
    ingressOtivViewer: null
    ingressSSLSecret: xecm-secret
    masterPassword: Opentext1!
    otac:
      enabled: true
    otacPublicUrl: https://otac.myubuntu6.hv
    otacc:
      enabled: false
    otaccPublicUrl: https://otacc.example.com
    otcs:
      enabled: true
    otcsPublicUrl: https://otcs.myubuntu6.hv
    otds:
      enabled: true
    otdsInCluster: true
    otdsPrivateUrl: null
    otdsPublicUrl: https://otds.myubuntu6.hv
    otdsServiceName: otds
    otdsUseReleaseName: false
    otiv:
      enabled: true
    otpd:
      enabled: false
    otpdPublicUrl: https://otpd.myubuntu6.hv
    otxecmctrl:
      enabled: true
    passwords:
      database:
        adminPassword: null
        ivPassword: null
    pdb:
      enabled: true
    priorityClasses:
      enabled: true
    resourceRequirements: false
    secretlink:
      enabled: false
      image:
        name: secretlink
        tag: 25.3.0
      loglevel: INFO
      vault: {}
    serviceAccountName: otxecm-sa
    serviceType: NodePort
    storageClassName: microk8s-hostpath
    storageClassNameNFS: microk8s-hostpath
    timeZone: Asia/Seoul
    trustedSourceOrigins: http://otcs-frontend
    trustedSourceOriginsAnonymous: null
  hostname: otac
  ilm:
    enabled: false
    tenant:
      name: OTAC
      shortname: OTAC
    users:
      access:
        userName: access.admin
      ba:
        userName: ba.admin
      ilm:
        userName: ilm.admin
      my:
        userName: my.admin
  image:
    name: otac
    tag: 24.4.3
  livenessProbe:
    enabled: true
    failureThreshold: 5
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 60
  objectimporter:
    enabled: false
    storage: 1Gi
  otds:
    admin: admin
    hostname: otdsws
    port: 80
    protocol: http
  otkm:
    enabled: false
  podAnnotations: {}
  poolName: Pool1
  port: 8080
  portProtocol: TCP
  preUpgradeJob:
    image:
      name: bitnami/kubectl
      tag: latest
  protocol: http
  pvc:
    labels:
      bdv: {}
      config: {}
      dv: {}
      logs: {}
      sd: {}
      sftpVolume: {}
  readinessProbe:
    enabled: true
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
  replicas: 1
  resType: AC
  resources:
    limits:
      cpu: 2
      memory: 3Gi
    requests:
      cpu: 1
      memory: 1.5Gi
  rmdir:
    retrycount: 2
    sleeptime: 50
  secretlink:
    image: {}
    vault: {}
  service:
    annotations: []
  serviceName: otac
  standardUserPasswords: {}
  targetPort: 8080
  tomcat:
    catalinaOpts: -Xmx2048m
  volumeDirectory: /opt/opentext/ac_sd/vol1
  volumeName: Vol1
  volumes:
    accessMode: ReadWriteOnce
    storage:
      bdv: 50Gi
      dv: 1Gi
      logs: 4Gi
      sd: 1Gi
otacc:
  cloud:
    insecure: false
  connector:
    reregister: false
  image:
    name: otacc
  port: 8080
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 1
      memory: 4Gi
otcs:
  additionalVolumes: []
  adminPodMonitor:
    enabled: false
    pod_monitor_client_id: otcs-podmonitor
  adminSettingsFolder: adminSettings
  config:
    adminRestartTime: 1
    awsStorageProvider: {}
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    contentProtection:
      enabled: false
    createAppMonitorUser: false
    createBizadminUser: false
    csResourceName: cs
    database:
      adminUsername: postgres
      autoExtendDataFile: true
      autoExtendLogFile: true
      mssql:
        dbDataFileSize: 500
        dbLogFileSize: 500
        master_database_name: master
      name: cs
      oracle:
        dbDataFileSize: 500
        dbDataFileSpec: /opt/oracle/cs.dbf
        loadTnsnames:
          enabled: false
          filename: tnsnames.ora
        serviceName: ORCLPDB1
        tnsnamesConnectionAlias: ORCL
      type: postgres
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    defaultAppsUpgrade: false
    deployBusinessScenarios: true
    deployTransportPackage: false
    documentStorage:
      efsPath: ""
      efsStorage: 1Gi
      type: otac
    enableMultiProcessMode: true
    enableSecurityLogs: false
    enableSynchronizedPartition: false
    enableSysmonLogs: false
    extensions:
      enabled: true
      includeManifestInitContainer: false
    gcpStorageProvider:
      serviceAccountJson: gcs_serviceaccount.json
    llm:
      clientID: LLM_Client
      enabled: false
    otac:
      archiveName: A1
      certFilename: sp.pem
      url: http://otac-0:8080
    otacc:
      archiveDescription: MyArchive
      archiveName: A1
      certFilename: sp.pem
      collectionName: Content Management
      coreUser: ba.test@username
      url: http://otacc:8080
    otds:
      displayName: OpenText Content Management CE 25.3
      port: 80
      sameSite:
        enabled: false
        value: None
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    port: 80
    proxy:
      enabled: false
      username: ""
    restartAutomationTime: 60
    search:
      localSearch:
        enabled: true
        storage: 1Gi
      memcached:
        autoMemcached: true
        servers: {}
      sharedSearch:
        enabled: false
        storage: 1Gi
    socketIPFamilyHint: 1
    storageProviderCache:
      enabled: false
      storage: 500Gi
    syndication:
      enabled: false
      isPrimary: false
    tomcat:
      accessLogsMaxDays: 7
      catalinaOpts: -Xmx1024m
    transportPackagesUrlList: []
    ual:
      certFilename: sp.pem
      enabled: false
    useExtendedECMLicense: false
    useExtendedECMLicese: false
  containerLogLevel: DEBUG
  contentServerAdmin:
    affinity: {}
    daWorkers: 0
    nodeSelector: {}
    podManagementPolicy: OrderedReady
    resources:
      limits:
        cpu: 2
        memory: 6Gi
      requests:
        cpu: 1
        memory: 6Gi
    sharedSearch:
      storage: 1Gi
    threadsNumber: 8
    tolerations: []
  contentServerBackendSearch:
    affinity: {}
    daWorkers: 0
    nodeSelector: {}
    podManagementPolicy: Parallel
    replicas: 1
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 1
        memory: 4Gi
    sharedSearch:
      storage: 1Gi
    threadsNumber: 8
    tolerations: []
  contentServerDa:
    affinity: {}
    daWorkers: 5
    nodeSelector: {}
    podManagementPolicy: Parallel
    replicas: 1
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 1
        memory: 4Gi
    threadsNumber: 1
    tolerations: []
  contentServerFrontend:
    affinity: {}
    daWorkers: 0
    nodeSelector: {}
    podManagementPolicy: Parallel
    replicas: 1
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 1
        memory: 4Gi
    threadsNumber: 8
    tolerations: []
  csAdminPorts:
  - name: tcp-admin-server
    port: 5858
  - name: tcp-document-conversion-server-admin
    port: 5868
  - name: tcp-document-conversion-server-rest-api
    port: 5869
  - name: tcp-enterprise-search-federator-search
    port: 8500
  - name: tcp-enterprise-search-federator-admin
    port: 8501
  - name: tcp-8502
    port: 8502
  - name: tcp-enterprise-update-distributor
    port: 8503
  - name: tcp-enterprise-document-conversion
    port: 8504
  - name: tcp-8505
    port: 8505
  - name: tcp-8506
    port: 8506
  - name: tcp-8507
    port: 8507
  - name: tcp-enterprise-search-engine-admin
    port: 8508
  - name: tcp-enterprise-search-engine-server
    port: 8509
  - name: tcp-enterprise-index-engine-admin
    port: 8510
  - name: tcp-enterprise-index-engine-server
    port: 8511
  - name: tcp-memcached-1
    port: 8512
  - name: tcp-memcached-2
    port: 8513
  - name: tcp-memcached-3
    port: 8514
  - name: tcp-9000
    port: 9000
  - name: tcp-9001
    port: 9001
  - name: tcp-9002
    port: 9002
  - name: tcp-9003
    port: 9003
  - name: tcp-9004
    port: 9004
  - name: tcp-9005
    port: 9005
  - name: tcp-9006
    port: 9006
  - name: tcp-9007
    port: 9007
  - name: tcp-9008
    port: 9008
  - name: tcp-9009
    port: 9009
  - name: tcp-9010
    port: 9010
  - name: tcp-9011
    port: 9011
  - name: tcp-9012
    port: 9012
  - name: tcp-9013
    port: 9013
  - name: tcp-9014
    port: 9014
  - name: tcp-9015
    port: 9015
  - name: tcp-9016
    port: 9016
  - name: tcp-9017
    port: 9017
  - name: tcp-9018
    port: 9018
  - name: tcp-9019
    port: 9019
  - name: tcp-9020
    port: 9020
  csPersist:
    logStorage: 5Gi
    storage: 6Gi
  fluentbit:
    customOutput:
      enabled: false
    enabled: false
    image:
      name: fluent/fluent-bit
      tag: 3.0.7
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
    logsToMonitor: []
    proxy:
      enableauthentication: false
      enabled: false
    readinessProbe:
      enabled: true
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
  global:
    amqp:
      password: null
    database:
      admin: postgres
      adminDatabase: postgres
      adminUsername: postgres
      hostname: 192.168.100.216
      ivName: otiv
      ivUsername: otiv
      password: Opentext1!
      port: 5432
      ssl: false
    existingLicenseSecret: null
    existingSecret: otxecm-default-secrets
    imagePullPolicy: IfNotPresent
    imagePullSecret: regcred
    imageSource: registry.opentext.com
    imageSourcePublic: docker.io
    ingressAnnotations:
      alb.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
      alb.ingress.kubernetes.io/target-type: ip
      kubernetes.io/ingress.allow-http: false
      nginx.ingress.kubernetes.io/affinity: cookie
      nginx.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
      nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
        nofollow";
    ingressAnnotationsCustom: {}
    ingressClass: nginx
    ingressDomainName: myubuntu6.hv
    ingressEnabled: true
    ingressIncludeNamespace: false
    ingressOtivAsset: null
    ingressOtivHighlight: null
    ingressOtivMarkup: null
    ingressOtivPublication: null
    ingressOtivViewer: null
    ingressSSLSecret: xecm-secret
    masterPassword: Opentext1!
    otac:
      enabled: true
    otacPublicUrl: https://otac.myubuntu6.hv
    otacc:
      enabled: false
    otaccPublicUrl: https://otacc.example.com
    otcs:
      enabled: true
    otcsPublicUrl: https://otcs.myubuntu6.hv
    otds:
      enabled: true
    otdsInCluster: true
    otdsPrivateUrl: null
    otdsPublicUrl: https://otds.myubuntu6.hv
    otdsServiceName: otds
    otdsUseReleaseName: false
    otiv:
      enabled: true
    otpd:
      enabled: false
    otpdPublicUrl: https://otpd.myubuntu6.hv
    otxecmctrl:
      enabled: true
    passwords:
      database:
        adminPassword: null
        ivPassword: null
    pdb:
      enabled: true
    priorityClasses:
      enabled: true
    resourceRequirements: false
    secretlink:
      enabled: false
      image:
        name: secretlink
        tag: 25.3.0
      loglevel: INFO
      vault: {}
    serviceAccountName: otxecm-sa
    serviceType: NodePort
    storageClassName: microk8s-hostpath
    storageClassNameNFS: microk8s-hostpath
    timeZone: Asia/Seoul
    trustedSourceOrigins: http://otcs-frontend
    trustedSourceOriginsAnonymous: null
  image:
    name: otxecm
    tag: 25.3.0
  ingress: {}
  initContainers: []
  istio:
    enabled: false
  kubectl:
    image:
      name: bitnami/kubectl
      tag: 1.30.4
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 600
    maxThreadLifespan: 10
    periodSeconds: 30
    timeoutSeconds: 15
  loadAdminSettings:
    enabled: false
  loadLicense:
    enabled: false
    filename: otxecmLicense.lic
  multifileStorage: 10Gi
  objectimporter:
    enabled: true
    storage: 1Gi
  otxecmctrl:
    customPayload:
      payloadConfig: {}
    image:
      name: otxecm-ctrl
      tag: 25.3.0
  passwords:
    dataEncryptionKey: /opt/opentext/cs/
    database:
      adminPassword: Opentext1!
    otacc: {}
    scenarioOwnerPassword: Opentext1!
    synchronizedPartition: {}
  podAnnotations: {}
  podLabels: {}
  pvc:
    contentProtection:
      labels: []
    csPersist:
      labels: []
    logs:
      labels: []
    sftpVolume:
      labels: []
  readinessProbe:
    enabled: true
    initialDelaySeconds: 0
    periodSeconds: 10
    timeoutSeconds: 6
  rootSquashNFS:
    enabled: false
    image:
      name: busybox
      tag: latest
  secretlink:
    image: {}
    vault: {}
  service:
    admin:
      annotations: []
    backendSearch:
      annotations: []
    frontend:
      annotations: []
    qds:
      annotations: []
  sharedAddressSpaceNat:
    enabled: false
otds:
  global:
    amqp:
      password: null
    database:
      admin: postgres
      adminDatabase: postgres
      adminUsername: postgres
      hostname: 192.168.100.216
      ivName: otiv
      ivUsername: otiv
      password: Opentext1!
      port: 5432
      ssl: false
    existingLicenseSecret: null
    existingSecret: otxecm-default-secrets
    extraPodMatchLabels: {}
    imagePullPolicy: IfNotPresent
    imagePullSecret: regcred
    imageSource: registry.opentext.com
    imageSourcePublic: docker.io
    ingressAnnotations:
      alb.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
      alb.ingress.kubernetes.io/target-type: ip
      kubernetes.io/ingress.allow-http: false
      nginx.ingress.kubernetes.io/affinity: cookie
      nginx.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
      nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
        nofollow";
    ingressAnnotationsCustom: {}
    ingressClass: nginx
    ingressDomainName: myubuntu6.hv
    ingressEnabled: true
    ingressIncludeNamespace: false
    ingressOtivAsset: null
    ingressOtivHighlight: null
    ingressOtivMarkup: null
    ingressOtivPublication: null
    ingressOtivViewer: null
    ingressSSLSecret: xecm-secret
    masterPassword: Opentext1!
    otac:
      enabled: true
    otacPublicUrl: https://otac.myubuntu6.hv
    otacc:
      enabled: false
    otaccPublicUrl: https://otacc.example.com
    otcs:
      enabled: true
    otcsPublicUrl: https://otcs.myubuntu6.hv
    otds:
      enabled: true
    otdsInCluster: true
    otdsPrivateUrl: null
    otdsPublicUrl: https://otds.myubuntu6.hv
    otdsServiceName: otds
    otdsUseReleaseName: false
    otiv:
      enabled: true
    otpd:
      enabled: false
    otpdPublicUrl: https://otpd.myubuntu6.hv
    otxecmctrl:
      enabled: true
    passwords:
      database:
        adminPassword: null
        ivPassword: null
    pdb:
      enabled: true
    priorityClasses:
      enabled: true
    resourceRequirements: false
    secretlink:
      enabled: false
      image:
        name: secretlink
        tag: 25.3.0
      loglevel: INFO
      vault: {}
    serviceAccountName: otxecm-sa
    serviceType: NodePort
    storageClassName: microk8s-hostpath
    storageClassNameNFS: microk8s-hostpath
    timeZone: Asia/Seoul
    trustedSourceOrigins: http://otcs-frontend
    trustedSourceOriginsAnonymous: null
  ingress:
    annotations: {}
    enabled: false
    exposeIndividualEndpoints: false
    paths:
    - /otds-admin/
    - /otdstenant/
    - /otdsws/
    - /ot-authws/
    - /otds-v2/
  otdsws:
    additionalJavaOpts: null
    adminEmail: null
    adminPassword: null
    affinity: null
    allowDuplicateUsers: true
    allowNonIndexedSearch: false
    carrierGradeNAT: true
    createRole: true
    cryptKey: Z2hkN2hyNDBkbWNGcVQ0TA==
    customSecretName: null
    emptyDirLimits:
      customTrustStoreDir: 16Mi
      initContainerDir: 128Mi
      logsDir: 1024Mi
      tempDir: 128Mi
      workDir: 128Mi
    enableBootstrapConfig: false
    enableCustomizedTruststore: false
    enabled: true
    existingBootstrapConfig: ""
    global:
      amqp:
        password: null
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      extraPodMatchLabels: {}
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressOtivAsset: null
      ingressOtivHighlight: null
      ingressOtivMarkup: null
      ingressOtivPublication: null
      ingressOtivViewer: null
      ingressSSLSecret: xecm-secret
      masterPassword: Opentext1!
      namespace: null
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsInCluster: true
      otdsPrivateUrl: null
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsServiceName: otds
      otdsUseReleaseName: false
      otiv:
        enabled: true
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      trustedSourceOrigins: http://otcs-frontend
      trustedSourceOriginsAnonymous: null
    image:
      name: otds-server
      pullPolicy: null
      pullSecret: null
      source: null
      tag: 25.3.0
    ingress:
      enabled: true
      prependPath: null
      secret: null
    initContainers: null
    isBizAdmin: false
    kerberos:
      configFile: ""
      enabled: false
      keytabFile: ""
    logging:
      logRequests: true
      logToFiles: false
      logToPVC: false
    migration:
      deploymentName: null
      enabled: false
      legacyImagePVC: null
      opendjUri: null
      password: null
      preUpgradeJob:
        enabled: false
        image:
          name: bitnami/kubectl
          source: null
          tag: latest
        resources:
          jvmMemory: null
          limits:
            cpu: 2
            memory: 3Gi
          requests:
            cpu: 0.5
            memory: 3Gi
        timeout: 100h
      serviceName: opendj
      servicePort: 1389
      usingLegacyImage: false
    newrelic:
      NEW_RELIC_APP_NAME: null
      NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT: false
      NEW_RELIC_LICENSE_KEY: null
      NEW_RELIC_LOG_FILE_NAME: STDOUT
      NEW_RELIC_LOG_LEVEL: info
    otdsdb:
      automaticDatabaseCreation:
        dbAdmin: null
        dbAdminPassword: null
        dbExtensions:
        - pg_trgm
        dbImage:
          name: bitnami/postgresql
          pullPolicy: null
          source: null
          tag: latest
        dbName: otdsdb
        enabled: false
      password: Opentext1!
      url: jdbc:postgresql://192.168.100.216:5432/otdsdb
      useDefaultSchema: false
      username: otdsuser
    podAnnotations: {}
    podLabels: {}
    port: 80
    portProtocol: TCP
    protocol: http
    publicHostname: null
    pvc:
      enabled: false
      storage: 256Mi
      storageClassName: null
    replicas: 1
    resources:
      enabled: null
      limits:
        cpu: 2
        memory: 3Gi
      requests:
        cpu: 1
        memory: 2Gi
    securityContext:
      fsGroup: 1000
      readOnlyRootFilesystem: false
      runAsGroup: 1000
      runAsUser: 1000
    serviceAccountName: null
    serviceAnnotations: {}
    serviceName: null
    serviceType: null
    singleCaCert: ""
    statefulSet: false
    systemGlobalOAuthClients: null
    targetPort: 8080
    timeZone: null
    tolerations: null
    topologySpreadConstraints: null
    vault:
      agentInjector: false
      authpath: auth/kubernetes
      dbBackendMountPath: database
      dbBackendRole: null
      enabled: false
      namespace: null
      proxyAddress: null
      role: null
      secretsPath: null
      tokenAudience: null
      url: http://localhost:8200
      useDynamicDbSecret: false
otiv:
  amqp:
    affinity: {}
    enabled: true
    extraSecrets: {}
    forceBoot:
      enabled: true
    fullnameOverride: otiv-amqp
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    image:
      debug: false
      name: otiv-amqp
      tag: 25.3.0
    ingress:
      annotations: {}
      enabled: false
      path: /
      tls: false
      tlsSecret: null
    ldap:
      enabled: false
      port: "389"
      server: ""
      tls:
        enabled: false
      user_dn_pattern: cn=${username},dc=example,dc=org
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 120
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 20
    metrics:
      annotations:
        prometheus.io/port: "9090"
        prometheus.io/scrape: "true"
      capabilities: bert,no_sort
      enabled: false
      env: {}
      image:
        name: bitnami/rabbitmq-exporter
        pullPolicy: IfNotPresent
        registry: docker.io
        tag: 0.29.0-debian-9-r104
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 15
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      port: 9419
      rabbitmqAddress: localhost
      readinessProbe:
        enabled: true
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      serviceMonitor:
        additionalLabels: {}
        enabled: false
        honorLabels: false
        interval: 30s
    networkPolicy:
      allowExternal: true
      enabled: false
    nodeSelector: {}
    persistence:
      accessMode: ReadWriteOnce
      enabled: true
      path: /mnt/data/var/lib/rabbitmq
      size: 1Gi
    podAnnotations: {}
    podDisruptionBudget: {}
    podLabels: {}
    podManagementPolicy: OrderedReady
    rabbitmq:
      advancedConfiguration: '[{rabbit, [ { default_consumer_prefetch, {false, 1}}
        ]}].'
      clustering:
        address_type: hostname
        k8s_domain: cluster.local
      configuration: |-
        loopback_users.guest = false
        listeners.tcp.default = 5672
        log.file = false
        log.console = true
        cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s
        cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
        cluster_formation.k8s.address_type = hostname
        cluster_formation.node_cleanup.only_log_warning = true
        consumer_timeout = 7200000
      env: {}
      extraPlugins: null
      loadDefinition:
        enabled: false
        secretName: null
      logs: '-'
      maxAvailableSchedulers: 2
      onlineSchedulers: 1
      password: Opentext1!
      plugins: rabbitmq_federation rabbitmq_management rabbitmq_peer_discovery_k8s
        rabbitmq_prometheus
      setUlimitNofiles: true
      tls:
        caCertificate: ""
        enabled: false
        failIfNoPeerCert: true
        serverCertificate: ""
        serverKey: ""
        sslOptionsVerify: verify_peer
      ulimitNofiles: "65536"
    rbacEnabled: true
    readinessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 10
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 20
    replicas: 1
    resources: {}
    securityContext:
      enabled: true
      extra: {}
      fsGroup: 1000
      runAsUser: 1000
    service:
      annotations: {}
      distPort: 25672
      managerPort: 15672
      port: 5672
      tlsPort: 5671
      type: ClusterIP
    tolerations: []
    updateStrategy:
      type: RollingUpdate
    volumePermissions:
      enabled: false
      image:
        name: bitnami/minideb
        pullPolicy: Always
        registry: docker.io
        tag: stretch
      resources: {}
  asset:
    auth:
      resource: false
    enabled: true
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 400m
        memory: 1Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-asset
      tag: 25.3.0
    ingress:
      enabled: true
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 100
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 3
    loglevel:
      example: DEBUG
    podLabels: {}
    publication:
      port: 80
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 10
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 500m
        memory: 1.2Gi
      requests:
        cpu: 250m
        memory: 0.6Gi
    service:
      albType: NodePort
      annotations: []
      port: 80
      targetPort: 9093
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 10
      failureThresholdCS: 80
      initialDelaySeconds: 35
      periodSeconds: 30
      timeoutSeconds: 2
    terminationGracePeriodSeconds: null
  config:
    auth:
      list: null
    enabled: true
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 1.1
        memory: 2.8Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-config
      tag: 25.3.0
    ingress:
      enabled: false
    ivShutdownDisabled: false
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 240
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 3
    loglevel:
      example: DEBUG
    podLabels: {}
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 10
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 500m
        memory: 2.5Gi
      requests:
        cpu: 250m
        memory: 1Gi
    service:
      annotations: []
      port: 80
      targetPort: 9678
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 12
      failureThresholdCS: 80
      initialDelaySeconds: 45
      periodSeconds: 30
      timeoutSeconds: 2
    terminationGracePeriodSeconds: null
  createServiceAccount: false
  global:
    amqp:
      host: otiv-amqp
      pwdKey: rabbitmq-password
      ssl: false
      user: user
      vhost: /
    counter: 1
    database:
      admin: postgres
      adminDatabase: postgres
      adminUsername: postgres
      hostname: 192.168.100.216
      ivName: otiv
      ivUsername: otiv
      password: Opentext1!
      port: 5432
      ssl: false
      sslMode: prefer
      type: postgresql
    dbSecretKey: OTIV_DB_ADMIN_PASSWORD
    enableForwarding: false
    enableOtivCustomizedTruststore: false
    enforceCorsOrigins: false
    enforceForwardedHosts: false
    existingLicenseSecret: null
    existingSecret: otxecm-default-secrets
    hazelport: 5701
    hpa:
      enabled: false
      targetType: averageValue
    imageBaseTag: 25.3.0
    imagePullPolicy: IfNotPresent
    imagePullSecret: regcred
    imageSource: registry.opentext.com
    imageSourcePublic: docker.io
    ingressAnnotations:
      alb.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
      alb.ingress.kubernetes.io/target-type: ip
      kubernetes.io/ingress.allow-http: false
      nginx.ingress.kubernetes.io/affinity: cookie
      nginx.ingress.kubernetes.io/configuration-snippet: |
        if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
      nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
        nofollow";
    ingressAnnotationsCustom: {}
    ingressClass: nginx
    ingressDomainName: myubuntu6.hv
    ingressEnabled: true
    ingressIncludeNamespace: false
    ingressSSLSecret: xecm-secret
    ipv6Enabled: false
    istioVirtualServicesEnabled: false
    ivDbSecretKey: OTIV_DB_PASSWORD
    k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
    logOutput: stdout
    masterPassword: Opentext1!
    newRelic:
      port: 3128
    nfsPersistenceSize: 20Gi
    otac:
      enabled: true
    otacPublicUrl: https://otac.myubuntu6.hv
    otacc:
      enabled: false
    otaccPublicUrl: https://otacc.example.com
    otcs:
      enabled: true
    otcsPublicUrl: https://otcs.myubuntu6.hv
    otds:
      enabled: true
    otdsCertUpdateInterval: 1440
    otdsInCluster: true
    otdsPublicUrl: https://otds.myubuntu6.hv
    otdsSecretKey: ADMIN_USER_PASSWORD
    otdsServiceName: otds
    otdsUseReleaseName: false
    otdsWebProtocol: https
    otiv:
      enabled: true
    otivPodLabels: {}
    otivSecretProviderClass:
      enabled: false
      provider: aws
      usePodIdentity: false
    otivSecretProviderClassCerts:
      enabled: false
      provider: aws
    otpd:
      enabled: false
    otpdPublicUrl: https://otpd.myubuntu6.hv
    otxecmctrl:
      enabled: true
    passwords:
      database:
        adminPassword: null
        ivPassword: null
    pdb:
      enabled: true
    priorityClasses:
      enabled: true
    proxy:
      excludes: otds|otcs-frontend|10.0.0.0/8
      port: 3128
    publicWebProtocol: https
    resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
    resourceRequirements: false
    secretlink:
      enabled: false
      image:
        name: secretlink
        tag: 25.3.0
      loglevel: INFO
      vault: {}
    service:
      annotations: []
    serviceAccountName: otxecm-sa
    serviceType: NodePort
    stopLegacyOtdsForUpgrade: false
    storageClassName: microk8s-hostpath
    storageClassNameNFS: microk8s-hostpath
    timeZone: Asia/Seoul
    transformationPodApiIPRanges: 10.0.0.0/32
    transformationPvcRWO: false
    trustedSourceOrigins: http://otcs-frontend
    usingServiceMesh: false
  highlight:
    clientId: iv-highlight
    clientSecret: null
    clientSecretKey: OTIV_HIGHLIGHT_CLIENT_SECRET
    clientSecretName: otiv-base-secrets
    enabled: true
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 400m
        memory: 0.6Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-highlight
      tag: 25.3.0
    ingress:
      enabled: true
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 120
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 2
    loglevel: info
    newRelic:
      loglevel: debug
    nodeOptions: null
    podLabels: {}
    publication:
      port: 80
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 5
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 300m
        memory: 512Mi
      requests:
        cpu: 50m
        memory: 256Mi
    service:
      albType: NodePort
      annotations: []
      port: 80
      targetPort: 3000
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 10
      failureThresholdCS: 80
      initialDelaySeconds: 35
      periodSeconds: 30
      timeoutSeconds: 2
  ingress:
    enabled: false
  initialization:
    image:
      name: otiv-config
      tag: 25.3.0
  markup:
    database:
      name: null
    dbMaxPoolSize: 10
    enableRoleBasedAccessControl: true
    enabled: true
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 400m
        memory: 0.6Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-markup
      tag: 25.3.0
    ingress:
      enabled: true
    jwtSecret: null
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 150
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 2
    loglevel: info
    newRelic:
      loglevel: debug
    nodeOptions: null
    podLabels: {}
    pwdKey: DB_PWD
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 5
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 300m
        memory: 256Mi
      requests:
        cpu: 50m
        memory: 64Mi
    service:
      albType: NodePort
      annotations: []
      port: 80
      targetPort: 3000
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 12
      failureThresholdCS: 80
      initialDelaySeconds: 45
      periodSeconds: 30
      timeoutSeconds: 2
  otcs:
    assetServiceUrl: http://otiv-asset
    csUriPath: /cs/cs
    highlightServiceUrl: http://otiv-highlight
    inCluster: true
    markupServiceUrl: http://otiv-markup
    otcsServiceUrl: http://otcs-frontend
    publicationServiceUrl: http://otiv-publication
    serviceUrl: http://otcs-frontend
    viewerServiceUrl: http://otiv-viewer
  publication:
    accessCheckTimeoutSeconds: 3
    clientId: iv-publication
    clientSecret: null
    clientSecretKey: OTIV_PUBLICATION_CLIENT_SECRET
    clientSecretName: otiv-base-secrets
    enableAccessCache: true
    enableCssCompositeDelivery: false
    enabled: true
    forceHttpsProtocol: false
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 1.5
        memory: 3.5Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-publication
      tag: 25.3.0
    ingress:
      enabled: true
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 240
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 3
    loglevel:
      example: DEBUG
    monitoring:
      clientId: iv-monitoring
      clientSecret: null
      clientSecretKey: OTIV_MONITOR_CLIENT_SECRET
      clientSecretName: otiv-base-secrets
    podLabels: {}
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 10
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 1.5
        memory: 1.5Gi
      requests:
        cpu: 200m
        memory: 1Gi
    service:
      albType: NodePort
      annotations: []
      port: 80
      targetPort: 9091
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 12
      failureThresholdCS: 80
      initialDelaySeconds: 45
      periodSeconds: 30
      timeoutSeconds: 2
    terminationGracePeriodSeconds: null
  publisher:
    clientId: iv-publisher
    clientSecret: null
    clientSecretKey: OTIV_PUBLISHER_CLIENT_SECRET
    clientSecretName: otiv-base-secrets
    cssUploadTimeout: null
    enabled: true
    fipsEnabled: false
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 2.2
        memory: 3.5Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 150
        stabilizationWindowSeconds: 400
      scaleUp:
        periodSeconds: 80
        stabilizationWindowSeconds: 400
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-publisher
      tag: 25.3.0
    livenessProbe:
      enabled: true
      failureThreshold: 4
      initialDelaySeconds: 300
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 10
    loglevel:
      example: DEBUG
    markup:
      port: 80
    metricsProvider: dropwizard
    podLabels: {}
    readinessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 10
      periodSeconds: 60
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 640Mi
    service:
      annotations: []
      port: 80
      targetPort: 9092
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 14
      failureThresholdCS: 80
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 2
    terminationGracePeriodSeconds: 60
    writeMarkups: true
  resourceSecretKey: resource
  singleCaCert: ""
  viewer:
    enabled: true
    global:
      amqp:
        host: otiv-amqp
        pwdKey: rabbitmq-password
        ssl: false
        user: user
        vhost: /
      counter: 1
      database:
        admin: postgres
        adminDatabase: postgres
        adminUsername: postgres
        hostname: 192.168.100.216
        ivName: otiv
        ivUsername: otiv
        password: Opentext1!
        port: 5432
        ssl: false
        sslMode: prefer
        type: postgresql
      dbSecretKey: OTIV_DB_ADMIN_PASSWORD
      enableForwarding: false
      enableOtivCustomizedTruststore: false
      enforceCorsOrigins: false
      enforceForwardedHosts: false
      existingLicenseSecret: null
      existingSecret: otxecm-default-secrets
      hazelport: 5701
      hpa:
        enabled: false
        targetType: averageValue
      imageBaseTag: 25.3.0
      imagePullPolicy: IfNotPresent
      imagePullSecret: regcred
      imageSource: registry.opentext.com
      imageSourcePublic: docker.io
      ingressAnnotations:
        alb.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1800
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30
        alb.ingress.kubernetes.io/target-type: ip
        kubernetes.io/ingress.allow-http: false
        nginx.ingress.kubernetes.io/affinity: cookie
        nginx.ingress.kubernetes.io/configuration-snippet: |
          if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-buffer-size: 16k
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
        nginx.ingress.kubernetes.io/server-snippet: add_header X-Robots-Tag "noindex,
          nofollow";
      ingressAnnotationsCustom: {}
      ingressClass: nginx
      ingressDomainName: myubuntu6.hv
      ingressEnabled: true
      ingressIncludeNamespace: false
      ingressSSLSecret: xecm-secret
      ipv6Enabled: false
      istioVirtualServicesEnabled: false
      ivDbSecretKey: OTIV_DB_PASSWORD
      k8sApiIPRanges: 10.0.0.0/32,172.0.0.0/32
      logOutput: stdout
      masterPassword: Opentext1!
      newRelic:
        port: 3128
      nfsPersistenceSize: 20Gi
      otac:
        enabled: true
      otacPublicUrl: https://otac.myubuntu6.hv
      otacc:
        enabled: false
      otaccPublicUrl: https://otacc.example.com
      otcs:
        enabled: true
      otcsPublicUrl: https://otcs.myubuntu6.hv
      otds:
        enabled: true
      otdsCertUpdateInterval: 1440
      otdsInCluster: true
      otdsPublicUrl: https://otds.myubuntu6.hv
      otdsSecretKey: ADMIN_USER_PASSWORD
      otdsServiceName: otds
      otdsUseReleaseName: false
      otdsWebProtocol: https
      otiv:
        enabled: true
      otivPodLabels: {}
      otivSecretProviderClass:
        enabled: false
        provider: aws
        usePodIdentity: false
      otivSecretProviderClassCerts:
        enabled: false
        provider: aws
      otpd:
        enabled: false
      otpdPublicUrl: https://otpd.myubuntu6.hv
      otxecmctrl:
        enabled: true
      passwords:
        database:
          adminPassword: null
          ivPassword: null
      pdb:
        enabled: true
      priorityClasses:
        enabled: true
      proxy:
        excludes: otds|otcs-frontend|10.0.0.0/8
        port: 3128
      publicWebProtocol: https
      resourceGuid: 4b9fb208-5a47-4585-97bd-7f38b4cc3d12
      resourceRequirements: false
      secretlink:
        enabled: false
        image:
          name: secretlink
          tag: 25.3.0
        loglevel: INFO
        vault: {}
      service:
        annotations: []
      serviceAccountName: otxecm-sa
      serviceType: NodePort
      stopLegacyOtdsForUpgrade: false
      storageClassName: microk8s-hostpath
      storageClassNameNFS: microk8s-hostpath
      timeZone: Asia/Seoul
      transformationPodApiIPRanges: 10.0.0.0/32
      transformationPvcRWO: false
      trustedSourceOrigins: http://otcs-frontend
      usingServiceMesh: false
    hpa:
      averageValue:
        cpu: 400m
        memory: 0.6Gi
      replicas:
        max: 3
        min: 1
      scaleDown:
        periodSeconds: 120
        stabilizationWindowSeconds: 300
      scaleUp:
        periodSeconds: 60
        stabilizationWindowSeconds: 300
      targetType: null
      utilization:
        cpu: 70
        memory: 70
    image:
      name: otiv-viewer
      tag: 25.3.0
    ingress:
      enabled: true
    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 100
      initialDelaySecondsCS: 1800
      periodSeconds: 30
      timeoutSeconds: 2
    loglevel: info
    newRelic:
      loglevel: debug
    nodeOptions: null
    podLabels: {}
    readinessProbe:
      enabled: true
      failureThreshold: 2
      initialDelaySeconds: 5
      periodSeconds: 25
      timeoutSeconds: 2
    replicas: 1
    resources:
      enabled: false
      limits:
        cpu: 250m
        memory: 256Mi
      requests:
        cpu: 20m
        memory: 128Mi
    service:
      albType: NodePort
      annotations: null
      port: 80
      targetPort: 3000
      type: ClusterIP
    startupProbe:
      enabled: true
      failureThreshold: 10
      failureThresholdCS: 80
      initialDelaySeconds: 35
      periodSeconds: 30
      timeoutSeconds: 2
otpd:
  admin: powerdocsadmin
  database:
    hostname: 192.168.100.216
  emailServerSettings:
    enabled: false
  hostname: otpd
  image:
    name: otpd
  loadLicense: false
  monitorUser: powerdocsmonitoruser
  otcs:
    enabled: true
  otds:
    admin: admin
  otpdLicense: otpdLicense.lic
  port: 8080
  protocol: http
  serviceName: otpd
  targetPort: 8080
  technicalUser: pduser
  technicalUserPassword: Opentext1!
  user: powerdocsuser
preUpgradeJob:
  image:
    name: bitnami/kubectl
    source: null
    tag: latest
  otxecm:
    forceRestart: false
preUpgradeJobDBCheck:
  image:
    name: postgres
    source: null
    tag: 13
rabbitmq:
  persistence:
    storageClass: null

HOOKS:
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
# Service Account required for the pre-upgrade job
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otac-pre-upgrade-job-sa
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otac
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-pvc-sa
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-job-sa
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-deployment-sa
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-delete-secrets-sa
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-delete-amqp-sa
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
---
# Source: otxecm/templates/pre-upgrade-job.yaml
# Service Account required for the pre-upgrade job
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otxecm-pre-upgrade-job-sa
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
---
# Source: otxecm/templates/otxecm-default-secrets.yaml
########################################################################
# OpenText Content Server Default Kubernetes Secrets
########################################################################
## This is a default secrets file that will be used if you are not creating your own kubernetes secret.
apiVersion: v1
kind: Secret
metadata:
  name: otxecm-default-secrets
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
data:
# Ensure password synchronization between OTCS, OTDS  and OTAC
  ## ADMIN_USER_PASSWORD determines the admin user. This must match OTDS_PASS below.
  ADMIN_USER_PASSWORD: T3BlbnRleHQxIQ==
  ## ADMIN_SERVER_PASSWORD determines the admin server password.
  ADMIN_SERVER_PASSWORD: T3BlbnRleHQxIQ==
  ## AUTO_SYS_ADMIN_PASSWORD determines the system admin user password.
  AUTO_SYS_ADMIN_PASSWORD: T3BlbnRleHQxIQ==
  ## SYS_SUPPORT_PASSWORD is the current password for the sys_support user
  SYS_SUPPORT_PASSWORD: T3BlbnRleHQxIQ==
  ## ALFILTER_USER_PASSWORD determines the ALFilter user password.
  ALFILTER_USER_PASSWORD: T3BlbnRleHQxIQ==
  ## DATA_ENCRYPTION_KEY determines the DEK password
  ## The DATA_ENCRYPTION_KEY must be set if secrets are being used
  DATA_ENCRYPTION_KEY: L29wdC9vcGVudGV4dC9jcy8=
  ## OTCS_DB_ADMIN_PASSWORD is the administrative database user (usually postgres for a postgres db or system for an oracle db) password of otcs
  OTCS_DB_ADMIN_PASSWORD: T3BlbnRleHQxIQ==
  ## DB_PASSWORD is the password of the user that owns the otcs database
  DB_PASSWORD: T3BlbnRleHQxIQ==
  ## TARGET_DB_PASSWORD is the password of the user that owns the otac database
  TARGET_DB_PASSWORD: T3BlbnRleHQxIQ==
  ## OTAC_DB_ADMIN_PASSWORD is the administrative database user (usually postgres) password of otac
  OTAC_DB_ADMIN_PASSWORD: T3BlbnRleHQxIQ==
  ## OTDS_PASS is the admin user password for otds. This must match ADMIN_USER_PASSWORD above.
  OTDS_PASS: T3BlbnRleHQxIQ==
  ## OTDS_JAKARTA_PERSISTENCE_JDBC_USER is the otds database username
  OTDS_JAKARTA_PERSISTENCE_JDBC_USER: b3Rkc3VzZXI=
  ## OTDS_JAKARTA_PERSISTENCE_JDBC_PASSWORD is the otds database password
  OTDS_JAKARTA_PERSISTENCE_JDBC_PASSWORD: T3BlbnRleHQxIQ==
  ## OTDS_DIRECTORY_BOOTSTRAP_INITIALPASSWORD is the admin user password for otds. It must match
  ## the passwords OTDS_PASS, ADMIN_USER_PASSWORD, OTDS_PASSWORD, OTCS_ADMIN_PASSWORD
  OTDS_DIRECTORY_BOOTSTRAP_INITIALPASSWORD: T3BlbnRleHQxIQ==
  ## OTDS_DIRECTORY_BOOTSTRAP_CRfYPTSECRET is used for secure synchronized access to backend DB from
  ## frontend instances. The value is a 16 character ASCII string that has been base64 encoded, and
  ## as such must be double base64 encoded here.
  OTDS_DIRECTORY_BOOTSTRAP_CRYPTSECRET: WjJoa04yaHlOREJrYldOR2NWUTBUQT09
  ## OTDS_DIRECTORY_BOOTSTRAP_PASSWORD is only required for migrations where there is a need to connect
  ## to an existing otds deployment
  ## OTDS_DB_ADMIN_PASSWORD is the administrative database user (usually postgres for a postgres db or system for an oracle db) password of otds
  OTDS_DB_ADMIN_PASSWORD: T3BlbnRleHQxIQ==
  ## OTIV_DB_ADMIN_PASSWORD is the db admin password used by OTIV to create and initialize the OTIV database
  OTIV_DB_ADMIN_PASSWORD: T3BlbnRleHQxIQ==
  ## OTIV_DB_PASSWORD is the db password used by the OTIV services db user to connect with the OTIV database
  OTIV_DB_PASSWORD: T3BlbnRleHQxIQ==
  rabbitmq-password: T3BlbnRleHQxIQ==
  OTIV_PUBLICATION_CLIENT_SECRET: UWo5eXpHc29FaWgzMXJLMQ==
  OTIV_MONITOR_CLIENT_SECRET: S0JVQzgyNG5TZ3FUOXM3Zw==
  OTIV_PUBLISHER_CLIENT_SECRET: T1JWYUJ2dm5ZQ1ZaS0R4TQ==
  OTIV_HIGHLIGHT_CLIENT_SECRET: RDJGaUlZSzNqNXBaeVhEVg==
  OTIV_CS_CLIENT_SECRET: MEU4clJDbm9oN3NFTDVjag==
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: otac-cleaner-cm
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otac
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-2"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded    
data:
  otac-delete-old-pvc.sh: |
    #!/bin/bash
    upgrade="24.4.3"
    upgradeRelease=$(awk -F. '{print $1"."$2}' <<< $upgrade)
    echo "Upgrade to ${upgrade} - Release ${upgradeRelease}"
    echo "Starting otac-pvc-cleaner"
    PVC_LIST=("otac-opentext-landscape-otac-0" "otac-tomcat-logs-otac-0")
    for PVC_NAME in "${PVC_LIST[@]}"; do
      if kubectl get pvc "$PVC_NAME" >/dev/null 2>&1; then
        echo "PVC $PVC_NAME found. Deleting..."
        kubectl delete pvc $PVC_NAME
      else
        echo "PVC $PVC_NAME does not exist. Skipping."
      fi
    done
  otac-delete-old-cm.sh: |
    #!/bin/bash
    echo "Starting otac-cm-cleaner"
    if kubectl get cm otac-pre-upgrade-configmap >/dev/null 2>&1; then
      echo "configMap - otac-pre-upgrade-configmap found. Deleting..."
      kubectl delete cm otac-pre-upgrade-configmap
    else
      echo "otac-pre-upgrade-configmap does not exist. Skipping."
    fi
---
# Source: otxecm/templates/pre-upgrade-job.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: otxecm-pre-upgrade
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded    
data:
  pre-upgrade.sh: |
    #!/bin/bash
    echo "Starting pre-Upgrade script"
    installed=$(kubectl get secret -l owner=helm,status=deployed -o json | jq -r '.items[] | select(.metadata.labels.name=="xecm-release").data.release' | base64 -d | base64 -d  | gzip -d | jq -r ".chart.metadata.version")
    installedRelease=$(awk -F. '{print $1"."$2}' <<< $installed)
    echo "Current installed ${installed} - Release ${installedRelease}"
    
    upgrade="25.3.0"
    upgradeRelease=$(awk -F. '{print $1"."$2}' <<< $upgrade)
    echo "Upgrade to ${upgrade} - Release ${upgradeRelease}"

    if [[ "$FORCE_RESTART" == "true" || "$installedRelease" != "$upgradeRelease" ]]; then
        echo "Upgrade Release - delete statefulsets"

        kubectl delete sts otac --ignore-not-found=true
        kubectl delete sts otpd --ignore-not-found=true 
        kubectl delete sts otcs-frontend --ignore-not-found=true 
        kubectl delete sts otcs-admin --ignore-not-found=true
        kubectl delete sts otcs-backend-search --ignore-not-found=true
        kubectl delete sts otcs-da --ignore-not-found=true
        kubectl delete services --ignore-not-found=true otcs-backend-search
        kubectl wait --for=delete pod/otcs-admin-0 --timeout=60s
    else
        kubectl rollout restart sts otcs-admin otcs-frontend otcs-backend-search otcs-da
    fi

    kubectl delete configmap otcs-state-configmap --ignore-not-found=true
---
# Source: otxecm/charts/otac/templates/otac-pvc.yaml
# Check if otac-config pvc exists if dosent exits proceed
# Check if otac-otac-0 pvc exists if dosent exits proceed
# Pre-install case requires the helm to create volume
# Pre-upgrade is not required as the volume will already will be present if the customer installs 22.3.0
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: otac-config
  labels:
    {}
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "-2"
    helm.sh/resource-policy: keep
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: "microk8s-hostpath"
  resources:
    requests:
      storage: 5Gi
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
# RBAC role to be assigned to service account for the pre-upgrade cleanup job
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otac-pre-upgrade-job-role
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otac
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
rules:
- apiGroups: [""]
  resources: ["persistentvolumeclaims", "configmaps"]
  verbs: ["get", "list", "watch", "delete"]
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-pvc-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
rules:
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "create", "patch", "update"]
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-job-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
rules:
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list", "delete"]
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-deployment-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
rules:
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale" ]
  verbs: ["get", "patch" ]
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-delete-secrets-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "delete"]
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-delete-amqp-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
rules:
- apiGroups: ["apps"]
  resources: ["statefulsets"]
  verbs: ["get", "list", "delete" ]
- apiGroups: [""]
  resources: ["services" ]
  verbs: ["get", "list", "delete" ]
---
# Source: otxecm/templates/pre-upgrade-job.yaml
# RBAC role to be assigned to service account for the pre-upgrade job
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otxecm-pre-upgrade-job-role
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-6"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
rules:
- apiGroups: ["", "apps"]
  resources: ["services", "statefulsets","pods","secrets","configmaps","persistentvolumeclaims"]
  verbs: ["list", "delete", "get", "watch", "patch"]
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
# Binding the role with the service account for the pre-upgrade cleanup job
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otac-pre-upgrade-job-rbac
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otac
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otac-pre-upgrade-job-role
subjects:
- kind: ServiceAccount
  name: otac-pre-upgrade-job-sa
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-pvc-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-pvc-role
subjects:
- kind: ServiceAccount
  name: otiv-pvc-sa
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-job-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-job-role
subjects:
- kind: ServiceAccount
  name: otiv-job-sa
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-deployment-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-deployment-role
subjects:
- kind: ServiceAccount
  name: otiv-deployment-sa
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-delete-secrets-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-delete-secrets-role
subjects:
- kind: ServiceAccount
  name: otiv-delete-secrets-sa
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-delete-amqp-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-delete-amqp-role
subjects:
- kind: ServiceAccount
  name: otiv-delete-amqp-sa
---
# Source: otxecm/templates/pre-upgrade-job.yaml
# Binding the role with the service account for the pre-upgrade job
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otxecm-pre-upgrade-job-rbac
  labels:
    app.kubernetes.io/name: xecm-release
    helm.sh/chart: otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otxecm-pre-upgrade-job-role
subjects:
- kind: ServiceAccount
  name: otxecm-pre-upgrade-job-sa
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
# Pre-upgrade job definition for OTAC Container
apiVersion: batch/v1
kind: Job
metadata:
  name: otac-pre-upgrade-job
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-2"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    spec:
      securityContext:
        ## The fsGroup field specifies that group ID 1000 is associated
        ## with all Containers in the Pod. Group ID 1000 is also
        ## associated with the mounted volumes and with any files created
        ## in that volume.
        ## This will make volumes be mounted with 1000 group permissions.
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otac-pre-upgrade-job-sa
      containers:
      - name:  otac-pre-upgrade-container
        image: registry.opentext.com/otac:24.4.3
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash"]
        args: ["-c", '/opt/opentext/shell_scripts/update_script.sh > /opt/opentext/archive_center/ac_config/upgrade_24.4.3_20250822102559.log']
        volumeMounts:
        - mountPath: /opt/opentext/archive_center/ac_config
          name: config
          readOnly: false
        securityContext:
          allowPrivilegeEscalation: false
      restartPolicy: Never
      volumes:
        - name: config
          persistentVolumeClaim:
            claimName: otac-config
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otiv/templates/delete-amqp-pods.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: otiv-delete-amqp-pods
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 2
  template:
    metadata:
      name: otiv-delete-amqp-pods
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otiv-delete-amqp-sa
      imagePullSecrets:
      - name: regcred
      containers:
      - name: otiv-delete-amqp-pods
        image: registry.opentext.com/otiv-config:25.3.0
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
          limits:
            cpu: 300m
            memory: 384Mi
        securityContext:
          allowPrivilegeEscalation: false
        command:
          - sh
        args: [ "-c",
                "sleep 1;
                 v=`kubectl get sts otiv-amqp -o=jsonpath='{.spec.template.spec.containers[0].image}' | cut -d':' -f 2`;
                 echo $v;
                 amqpImageTagMajorVersion=${v:0:4};
                 bitnamiAmqp=`echo \"$amqpImageTagMajorVersion < 24.25\" | bc -l`;
                 if [ $bitnamiAmqp -eq 1 ];
                  then
                  output=`kubectl delete statefulset --ignore-not-found otiv-amqp`;
                  echo $output;
                  output2=`kubectl delete service --ignore-not-found otiv-amqp-headless otiv-amqp`;
                  echo $output2;
                  if [ \"$?\" -eq \"0\" ];
                    then
                      echo \"amqp pod deleted; Continuing.\";
                    else
                      echo \"amqp pod didn't exist; Continuing.\";
                  fi;
                 fi
             "]
---
# Source: otxecm/charts/otiv/templates/delete-lock-secrets.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: otiv-delete-lock-secrets
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 2
  template:
    metadata:
      name: otiv-delete-lock-secrets
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otiv-delete-secrets-sa
      imagePullSecrets:
      - name: regcred
      containers:
      - name: delete-lock-secrets
        image: registry.opentext.com/otiv-config:25.3.0
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
          limits:
            cpu: 300m
            memory: 384Mi
        securityContext:
          allowPrivilegeEscalation: false
        command:
          - sh
        args: [ "-c",
                "sleep 1;
                 output=`kubectl delete secrets otiv-resourcel-lock otiv-metis-lock otiv-highlight-lock otiv-publication-lock otiv-publisher-lock`;
                 if [ \"$?\" -eq \"0\" ];
                 then
                     echo \"Secrets deleted; Continuing.\";
                 else
                     echo \"Secrets didn't exist; Continuing.\";
                 fi;" ]
---
# Source: otxecm/charts/otiv/templates/delete-vat-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: otiv-delete-cs-vat-job
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,pre-rollback
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 1
  template:
    metadata:
      name: otiv-delete-cs-vat-job
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otiv-job-sa
      imagePullSecrets:
      - name: regcred
      containers:
      - name: delete-vat
        image: registry.opentext.com/otiv-config:25.3.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
        command:
          - sh
        args: [ "-c",
                "sleep 4;
                 JOB_NAME=otiv-cs-vat-job;
                 output=`kubectl get job $JOB_NAME`;
                 if [ \"$?\" -eq \"0\" ];
                 then
                     kubectl delete job $JOB_NAME;
                 else
                     echo \"Job $JOB_NAME does not exist; Continuing.\";
                 fi;" ]
---
# Source: otxecm/charts/otiv/templates/pvc-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: otiv-pvc-job
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 1
  template:
    metadata:
      name: otiv-pvc-job
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otiv-pvc-sa
      imagePullSecrets:
      - name: regcred
      containers:
      - name: pvc-rwx
        image: registry.opentext.com/otiv-config:25.3.0
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
          limits:
            cpu: 300m
            memory: 384Mi
        securityContext:
          allowPrivilegeEscalation: false
        env:
          - name: STORAGE_SIZE
            value: 20Gi
          - name: STORAGE_CLASS_NAME
            value: microk8s-hostpath
          - name: ACCESS_MODE
            value: ReadWriteMany
          - name: TZ
            value: 'Asia/Seoul'
        command:
          - sh
        args: [ "-c",
                "printf \"kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: otiv-bas\nspec:\n\" > /tmp/pvc.yaml;
                 printf \"  storageClassName: $(STORAGE_CLASS_NAME)\n\" >> /tmp/pvc.yaml;
                 printf \"  accessModes:\n    - $(ACCESS_MODE)\n\" >> /tmp/pvc.yaml;
                 printf \"  resources:\n    requests:\n      storage: $(STORAGE_SIZE)\n\" >> /tmp/pvc.yaml;
                 kubectl apply -f /tmp/pvc.yaml;" ]
---
# Source: otxecm/charts/otiv/templates/stop-transformation-pods.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: stop-transformation-pods
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 2
  template:
    metadata:
      name: stop-transformation-pods
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otiv-deployment-sa
      imagePullSecrets:
      - name: regcred
      containers:
      - name: stop-transformation-pods
        image: registry.opentext.com/otiv-config:25.3.0
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
          limits:
            cpu: 300m
            memory: 384Mi
        securityContext:
          allowPrivilegeEscalation: false
        env:
        command:
          - ./scripts/stopPodsForUpgrade.sh
---
# Source: otxecm/templates/pre-upgrade-job.yaml
# Pre-upgrade job definition
apiVersion: batch/v1
kind: Job
metadata:
  name: otxecm-pre-upgrade-job
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      annotations:
        "sidecar.istio.io/inject": "false"
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otxecm-pre-upgrade-job-sa
      containers:
      - name:  otxecm-pre-upgrade-container
        image: docker.io/bitnami/kubectl:latest
        command: ["sh"]
        args:
          - "-c"
          - "/script/pre-upgrade.sh"
        env:
          - name: FORCE_RESTART
            value: "false"
        securityContext:
          allowPrivilegeEscalation: false
        volumeMounts:
        - name: otxecm-pre-upgrade
          mountPath: /script/
      volumes:
      - name: otxecm-pre-upgrade
        configMap:
          name: otxecm-pre-upgrade
          defaultMode: 0010
      dnsPolicy: ClusterFirst
---
# Source: otxecm/templates/pre-upgrade-job.yaml
# Pre-upgrade job definition
apiVersion: batch/v1
kind: Job
metadata:
  name: otxecm-pre-upgrade-job-db-check
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      annotations:
        "sidecar.istio.io/inject": "false"
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: OnFailure
      serviceAccountName: otxecm-pre-upgrade-job-sa
      containers:
      - name:  otxecm-pre-upgrade-container
        image: docker.io/postgres:13
        command: ["pg_isready"]
        args:
          - "-d"
          - "postgres"
          - "-h"
          - "192.168.100.216"
          - "-p" 
          - "5432"
          - "-U"
          - "postgres"
          - "-t"
          - "10"
        securityContext:
          allowPrivilegeEscalation: false
MANIFEST:
---
# Source: otxecm/templates/otxecm-priority.yaml
# Enables PriorityClasses:
# this allows us to evict lower priority pods, 
# which allows us to scale on smaller nodes
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
    name: xecm-release-default-1
value: 1000
globalDefault: false
description: "This priority class should be used for central service pods only."
---
# Source: otxecm/templates/otxecm-priority.yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
    name: xecm-release-default-2
value: 900
globalDefault: false
description: "This priority class should be used for services that require high-priority services"
---
# Source: otxecm/templates/otxecm-PodDisruptionBudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: otcs-frontend
spec:
  minAvailable: "40%"
  selector:
    matchLabels:
      app.kubernetes.io/component: otcs-frontend
---
# Source: otxecm/templates/otxecm-PodDisruptionBudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: otdsws
spec:
  minAvailable: "40%"
  selector:
    matchLabels:
      app.kubernetes.io/component: otdsws
---
# Source: otxecm/charts/otcs/templates/otxecm-ctrl-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  otxecm-ctrl
---
# Source: otxecm/charts/otiv/charts/amqp/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otiv-amqp
  labels:
    app: rabbitmq
    chart: rabbitmq-1
    release: "xecm-release"
    heritage: "Helm"
---
# Source: otxecm/templates/otxecm-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otxecm-sa
---
# Source: otxecm/charts/otac/templates/otac-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: otac-default-password
type: Opaque
data:
  OTAC_DEFAULT_PASSWORD: "T3BlbnRleHQxIQ=="
---
# Source: otxecm/charts/otiv/charts/amqp/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: otiv-amqp
  labels:
    app: rabbitmq
    chart: rabbitmq-1
    release: "xecm-release"
    heritage: "Helm"
type: Opaque
data:
  RABBITMQ_ERLANG_COOKIE: V0lXVkhDRFRDSVVBV0FOTE1RQVc=
  
  rabbitmq-erlang-cookie: "Nm5zWlhTT1hhU01yRnQ5ZzN6MTdmdVRydm9lbzlPZUU="
---
# Source: otxecm/charts/otac/templates/otac-configmaps.yaml
########################################################################
# OpenText Archive Center Kubernetes Configuration Maps
########################################################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: otac-configmap
  labels:
    app.kubernetes.io/name: otac
    helm.sh/chart: otac-24.4.3
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  ## AC config:
  bizHost: otac-0
  acProtocol: http
  resType: AC
  acPostAcConfig: "true"
  acArchiveName: A1
  acPoolName: Pool1
  acVolumeName: Vol1
  acVolumeDir: /opt/opentext/ac_sd/vol1
  OTXECM_SECRET_NAME: otxecm-default-secrets
  ## CMIS config:
  ## Database config:
  dbType: postgres
  dbSecureMode: "false"
  targetDBName: "ac"
  targetDBUserName: "ac"
  DBHOST: "192.168.100.216"
  DBPORT: "5432"
  DBUSER: "postgres"
  SID: ac
  oracleTSData: ac_data
  oracleTSIndex: ac_index
  postgresTSDefault: pg_default
  ## OTDS config:
  otdsAdmin: admin
  otdsTomcatHostname: "otds"
  otdsTomcatPort: "80"
  otdsTomcatProtocol: http
  SHARED_ADDRESS_SPACE_NAT: "false"
  runSchema: "true"
  TZ: Asia/Seoul
  GOOGLE_APPLICATION_CREDENTIALS: /opt/opentext/archive_center/ac_config/gcp.json
  ##Document encryption configuration
  encryptionEnabled: "false"
  
  ## Storage device config:
  ##GCS
  gcsEnable: "false"
  gcsDeviceName: "GCP"
  gcsServiceAddress: "storage.googleapis.com"
  gcsBucketAddressStyle: "VIRTUAL_HOST_STYLE"
  gcsVolumeName: "volgcs1"
  gcsServiceAccountJSONFileName: "gcs_serviceaccount.json"
  gcsstorageProxy: X
  acArchiveName2: "A2"
  useServiceAccount: "false"
  gcsglobalretentionmode: COMPLIANCE
  gcsobjectretentionmode: X
  
  ##S3
  s3Enable: "false"
  s3DeviceName: "S3"
  s3ServiceAddress: "s3.amazonaws.com"
  s3BucketAddressStyle: "VIRTUAL_HOST_STYLE"
  s3VolumeName: "vols31"
  s3storageProxy: X
  acArchiveName3: "A3"
  s3UseRoleBasedAuth: "false"
  s3globalretentionmode: COMPLIANCE
  s3objectretentionmode: X
  
  ##AZURE
  azureEnable: "false"
  azureDeviceName: "AZURE"
  azureHost: "https://blob.core.windows.net:443"
  azureVolumeName: "volazure1"
  azurestorageProxy: X
  acArchiveName4: "A4"

  ## Validation of certificates

  ## Tomcat CATALINA_OPTS
  catalinaOpts: "-Xmx2048m"

  ## SecretLink :
  SL_ENABLED: "false"
---
# Source: otxecm/charts/otac/templates/otac-configmaps.yaml
########################################################################
# Tnsnames.ora ##UPDATE
########################################################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: otac-tnsnames-configmap
  labels:
    app.kubernetes.io/name: otac
    helm.sh/chart: otac-24.4.3
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  tnsnames.ora: ac=(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=example.com)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=ac)))
---
# Source: otxecm/charts/otac/templates/otac-configmaps.yaml
########################################################################
# tomcat files ##UPDATE
########################################################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: otac-tomcatfiles-configmap
  labels:
    app.kubernetes.io/name: otac
    helm.sh/chart: otac-24.4.3
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  logging.properties: |-
    # Licensed to the Apache Software Foundation (ASF) under one or more
    # contributor license agreements.  See the NOTICE file distributed with
    # this work for additional information regarding copyright ownership.
    # The ASF licenses this file to You under the Apache License, Version 2.0
    # (the "License"); you may not use this file except in compliance with
    # the License.  You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    handlers = 1catalina.org.apache.juli.AsyncFileHandler, 2localhost.org.apache.juli.AsyncFileHandler, 3manager.org.apache.juli.AsyncFileHandler, 4host-manager.org.apache.juli.AsyncFileHandler, java.util.logging.ConsoleHandler
    
    .handlers = 1catalina.org.apache.juli.AsyncFileHandler
    
    ############################################################
    # Handler specific properties.
    # Describes specific configuration info for Handlers.
    ############################################################
    
    1catalina.org.apache.juli.AsyncFileHandler.level = WARNING
    1catalina.org.apache.juli.AsyncFileHandler.directory = /opt/opentext/logs
    1catalina.org.apache.juli.AsyncFileHandler.prefix = catalina.
    
    2localhost.org.apache.juli.AsyncFileHandler.level = WARNING
    2localhost.org.apache.juli.AsyncFileHandler.directory = /opt/opentext/logs
    2localhost.org.apache.juli.AsyncFileHandler.prefix = localhost.
    
    3manager.org.apache.juli.AsyncFileHandler.level = WARNING
    3manager.org.apache.juli.AsyncFileHandler.directory = /opt/opentext/logs
    3manager.org.apache.juli.AsyncFileHandler.prefix = manager.
    
    4host-manager.org.apache.juli.AsyncFileHandler.level = WARNING
    4host-manager.org.apache.juli.AsyncFileHandler.directory = /opt/opentext/logs
    4host-manager.org.apache.juli.AsyncFileHandler.prefix = host-manager.
    
    java.util.logging.ConsoleHandler.level = WARNING
    java.util.logging.ConsoleHandler.formatter = org.apache.juli.OneLineFormatter
    
    
    ############################################################
    # Facility specific properties.
    # Provides extra control for each logger.
    ############################################################
    
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].level = WARNING
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].handlers = 2localhost.org.apache.juli.AsyncFileHandler
    
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].level = WARNING
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].handlers = 3manager.org.apache.juli.AsyncFileHandler
    
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].level = WARNING
    org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].handlers = 4host-manager.org.apache.juli.AsyncFileHandler
    
    # For example, set the org.apache.catalina.util.LifecycleBase logger to log
    # each component that extends LifecycleBase changing state:
    #org.apache.catalina.util.LifecycleBase.level = FINE
    
    # To see debug messages in TldLocationsCache, uncomment the following line:
    #org.apache.jasper.compiler.TldLocationsCache.level = FINE
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
# Content Server settings file yaml - da (distributed agent)
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-da-configmap
data:
  config.yaml: |-
    adminRestartTime: 1
    awsStorageProvider: {}
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    contentProtection:
      enabled: false
    createAppMonitorUser: false
    createBizadminUser: false
    csResourceName: cs
    database:
      adminUsername: postgres
      autoExtendDataFile: true
      autoExtendLogFile: true
      mssql:
        dbDataFileSize: 500
        dbLogFileSize: 500
        master_database_name: master
      name: cs
      oracle:
        dbDataFileSize: 500
        dbDataFileSpec: /opt/oracle/cs.dbf
        loadTnsnames:
          enabled: false
          filename: tnsnames.ora
        serviceName: ORCLPDB1
        tnsnamesConnectionAlias: ORCL
      type: postgres
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    defaultAppsUpgrade: false
    deployBusinessScenarios: true
    deployTransportPackage: false
    documentStorage:
      efsPath: ""
      efsStorage: 1Gi
      type: otac
    enableMultiProcessMode: true
    enableSecurityLogs: false
    enableSynchronizedPartition: false
    enableSysmonLogs: false
    extensions:
      enabled: true
      includeManifestInitContainer: false
    gcpStorageProvider:
      serviceAccountJson: gcs_serviceaccount.json
    llm:
      clientID: LLM_Client
      enabled: false
    otac:
      archiveName: A1
      certFilename: sp.pem
      url: http://otac-0:8080
    otacc:
      archiveDescription: MyArchive
      archiveName: A1
      certFilename: sp.pem
      collectionName: Content Management
      coreUser: ba.test@username
      url: http://otacc:8080
    otds:
      displayName: OpenText Content Management CE 25.3
      port: 80
      sameSite:
        enabled: false
        value: None
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    port: 80
    proxy:
      enabled: false
      username: ""
    restartAutomationTime: 60
    search:
      localSearch:
        enabled: true
        storage: 1Gi
      memcached:
        autoMemcached: true
        servers: {}
      sharedSearch:
        enabled: false
        storage: 1Gi
    socketIPFamilyHint: 1
    storageProviderCache:
      enabled: false
      storage: 500Gi
    syndication:
      enabled: false
      isPrimary: false
    tomcat:
      accessLogsMaxDays: 7
      catalinaOpts: -Xmx1024m
    transportPackagesUrlList: []
    ual:
      certFilename: sp.pem
      enabled: false
    useExtendedECMLicense: false
    useExtendedECMLicese: false
    podMonitor:
     enabled: false
     pod_monitor_client_id: otcs-podmonitor
    globalDatabase:
     admin: postgres
     adminDatabase: postgres
     adminUsername: postgres
     hostname: 192.168.100.216
     ivName: otiv
     ivUsername: otiv
     password: Opentext1!
     port: 5432
     ssl: false
    secretLinkEnabled: "false"
    threadsNumber: 1
    csurl: "https://otcs.myubuntu6.hv"
    daWorkers: 5
    otdssignInUrl: "https://otds.myubuntu6.hv"
    otdsserverUrl: "https://otds.myubuntu6.hv"
    otaccUrl: "https://otacc.example.com"
    otacEnabled: true
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
# Content Server settings file yaml - frontend
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-frontend-configmap
data:
  config.yaml: |-
    adminRestartTime: 1
    awsStorageProvider: {}
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    contentProtection:
      enabled: false
    createAppMonitorUser: false
    createBizadminUser: false
    csResourceName: cs
    database:
      adminUsername: postgres
      autoExtendDataFile: true
      autoExtendLogFile: true
      mssql:
        dbDataFileSize: 500
        dbLogFileSize: 500
        master_database_name: master
      name: cs
      oracle:
        dbDataFileSize: 500
        dbDataFileSpec: /opt/oracle/cs.dbf
        loadTnsnames:
          enabled: false
          filename: tnsnames.ora
        serviceName: ORCLPDB1
        tnsnamesConnectionAlias: ORCL
      type: postgres
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    defaultAppsUpgrade: false
    deployBusinessScenarios: true
    deployTransportPackage: false
    documentStorage:
      efsPath: ""
      efsStorage: 1Gi
      type: otac
    enableMultiProcessMode: true
    enableSecurityLogs: false
    enableSynchronizedPartition: false
    enableSysmonLogs: false
    extensions:
      enabled: true
      includeManifestInitContainer: false
    gcpStorageProvider:
      serviceAccountJson: gcs_serviceaccount.json
    llm:
      clientID: LLM_Client
      enabled: false
    otac:
      archiveName: A1
      certFilename: sp.pem
      url: http://otac-0:8080
    otacc:
      archiveDescription: MyArchive
      archiveName: A1
      certFilename: sp.pem
      collectionName: Content Management
      coreUser: ba.test@username
      url: http://otacc:8080
    otds:
      displayName: OpenText Content Management CE 25.3
      port: 80
      sameSite:
        enabled: false
        value: None
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    port: 80
    proxy:
      enabled: false
      username: ""
    restartAutomationTime: 60
    search:
      localSearch:
        enabled: true
        storage: 1Gi
      memcached:
        autoMemcached: true
        servers: {}
      sharedSearch:
        enabled: false
        storage: 1Gi
    socketIPFamilyHint: 1
    storageProviderCache:
      enabled: false
      storage: 500Gi
    syndication:
      enabled: false
      isPrimary: false
    tomcat:
      accessLogsMaxDays: 7
      catalinaOpts: -Xmx1024m
    transportPackagesUrlList: []
    ual:
      certFilename: sp.pem
      enabled: false
    useExtendedECMLicense: false
    useExtendedECMLicese: false
    podMonitor: 
     enabled: false
     pod_monitor_client_id: otcs-podmonitor
    globalDatabase: 
     admin: postgres
     adminDatabase: postgres
     adminUsername: postgres
     hostname: 192.168.100.216
     ivName: otiv
     ivUsername: otiv
     password: Opentext1!
     port: 5432
     ssl: false
    secretLinkEnabled: "false"
    threadsNumber: 8
    csurl: "https://otcs.myubuntu6.hv"
    daWorkers: 0
    otdssignInUrl: "https://otds.myubuntu6.hv"
    otdsserverUrl: "https://otds.myubuntu6.hv"
    otaccUrl: "https://otacc.example.com"
    otacEnabled: true
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
# Content Server settings file yaml - admin
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-admin-configmap
data:
  config.yaml: |-
    adminRestartTime: 1
    awsStorageProvider: {}
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    contentProtection:
      enabled: false
    createAppMonitorUser: false
    createBizadminUser: false
    csResourceName: cs
    database:
      adminUsername: postgres
      autoExtendDataFile: true
      autoExtendLogFile: true
      mssql:
        dbDataFileSize: 500
        dbLogFileSize: 500
        master_database_name: master
      name: cs
      oracle:
        dbDataFileSize: 500
        dbDataFileSpec: /opt/oracle/cs.dbf
        loadTnsnames:
          enabled: false
          filename: tnsnames.ora
        serviceName: ORCLPDB1
        tnsnamesConnectionAlias: ORCL
      type: postgres
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    defaultAppsUpgrade: false
    deployBusinessScenarios: true
    deployTransportPackage: false
    documentStorage:
      efsPath: ""
      efsStorage: 1Gi
      type: otac
    enableMultiProcessMode: true
    enableSecurityLogs: false
    enableSynchronizedPartition: false
    enableSysmonLogs: false
    extensions:
      enabled: true
      includeManifestInitContainer: false
    gcpStorageProvider:
      serviceAccountJson: gcs_serviceaccount.json
    llm:
      clientID: LLM_Client
      enabled: false
    otac:
      archiveName: A1
      certFilename: sp.pem
      url: http://otac-0:8080
    otacc:
      archiveDescription: MyArchive
      archiveName: A1
      certFilename: sp.pem
      collectionName: Content Management
      coreUser: ba.test@username
      url: http://otacc:8080
    otds:
      displayName: OpenText Content Management CE 25.3
      port: 80
      sameSite:
        enabled: false
        value: None
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    port: 80
    proxy:
      enabled: false
      username: ""
    restartAutomationTime: 60
    search:
      localSearch:
        enabled: true
        storage: 1Gi
      memcached:
        autoMemcached: true
        servers: {}
      sharedSearch:
        enabled: false
        storage: 1Gi
    socketIPFamilyHint: 1
    storageProviderCache:
      enabled: false
      storage: 500Gi
    syndication:
      enabled: false
      isPrimary: false
    tomcat:
      accessLogsMaxDays: 7
      catalinaOpts: -Xmx1024m
    transportPackagesUrlList: []
    ual:
      certFilename: sp.pem
      enabled: false
    useExtendedECMLicense: false
    useExtendedECMLicese: false
    podMonitor: 
     enabled: false
     pod_monitor_client_id: otcs-podmonitor
    globalDatabase:
     admin: postgres
     adminDatabase: postgres
     adminUsername: postgres
     hostname: 192.168.100.216
     ivName: otiv
     ivUsername: otiv
     password: Opentext1!
     port: 5432
     ssl: false
    secretLinkEnabled: "false"
    threadsNumber: 8
    csurl: "https://otcs.myubuntu6.hv"
    daWorkers: 0
    otdssignInUrl: "https://otds.myubuntu6.hv"
    otdsserverUrl: "https://otds.myubuntu6.hv"
    otaccUrl: "https://otacc.example.com"
    otacEnabled: true
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
# Content Server settings file yaml - backend search
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-backend-search-configmap
data:
  config.yaml: |-
    adminRestartTime: 1
    awsStorageProvider: {}
    businessScenariosList:
    - OT-Teamspaces
    - OT-Projects
    - OT-Agreements
    - OT-EAM
    - OT-REALESTATE
    - OT-Procurement
    contentProtection:
      enabled: false
    createAppMonitorUser: false
    createBizadminUser: false
    csResourceName: cs
    database:
      adminUsername: postgres
      autoExtendDataFile: true
      autoExtendLogFile: true
      mssql:
        dbDataFileSize: 500
        dbLogFileSize: 500
        master_database_name: master
      name: cs
      oracle:
        dbDataFileSize: 500
        dbDataFileSpec: /opt/oracle/cs.dbf
        loadTnsnames:
          enabled: false
          filename: tnsnames.ora
        serviceName: ORCLPDB1
        tnsnamesConnectionAlias: ORCL
      type: postgres
      useExistingDatabase: true
      username: postgres
    defaultAppsInstall: true
    defaultAppsUpgrade: false
    deployBusinessScenarios: true
    deployTransportPackage: false
    documentStorage:
      efsPath: ""
      efsStorage: 1Gi
      type: otac
    enableMultiProcessMode: true
    enableSecurityLogs: false
    enableSynchronizedPartition: false
    enableSysmonLogs: false
    extensions:
      enabled: true
      includeManifestInitContainer: false
    gcpStorageProvider:
      serviceAccountJson: gcs_serviceaccount.json
    llm:
      clientID: LLM_Client
      enabled: false
    otac:
      archiveName: A1
      certFilename: sp.pem
      url: http://otac-0:8080
    otacc:
      archiveDescription: MyArchive
      archiveName: A1
      certFilename: sp.pem
      collectionName: Content Management
      coreUser: ba.test@username
      url: http://otacc:8080
    otds:
      displayName: OpenText Content Management CE 25.3
      port: 80
      sameSite:
        enabled: false
        value: None
      trustedSites:
      - https://teams.microsoft.com
      - https://otawg.ubuntu-otcm.hv
    port: 80
    proxy:
      enabled: false
      username: ""
    restartAutomationTime: 60
    search:
      localSearch:
        enabled: true
        storage: 1Gi
      memcached:
        autoMemcached: true
        servers: {}
      sharedSearch:
        enabled: false
        storage: 1Gi
    socketIPFamilyHint: 1
    storageProviderCache:
      enabled: false
      storage: 500Gi
    syndication:
      enabled: false
      isPrimary: false
    tomcat:
      accessLogsMaxDays: 7
      catalinaOpts: -Xmx1024m
    transportPackagesUrlList: []
    ual:
      certFilename: sp.pem
      enabled: false
    useExtendedECMLicense: false
    useExtendedECMLicese: false
    podMonitor: 
     enabled: false
     pod_monitor_client_id: otcs-podmonitor
    globalDatabase: 
     admin: postgres
     adminDatabase: postgres
     adminUsername: postgres
     hostname: 192.168.100.216
     ivName: otiv
     ivUsername: otiv
     password: Opentext1!
     port: 5432
     ssl: false
    secretLinkEnabled: "false"
    threadsNumber: 8
    csurl: "https://otcs.myubuntu6.hv"
    daWorkers: 0
    otdssignInUrl: "https://otds.myubuntu6.hv"
    otdsserverUrl: "https://otds.myubuntu6.hv"
    otaccUrl: "https://otacc.example.com"
    otacEnabled: true
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
########################################################################
# Tracks the state of the otcs pods to figure out the automation steps required.
# If otcs-admin-0 or <pod-name>: unconfigured then full automation will run
# for either upgrade or initial deploy.
# If otcs-admin-0 and <pod-name>: configured only deploy webapps and other small tasks
########################################################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-state-configmap
---
# Source: otxecm/charts/otcs/templates/otcs-configmaps.yaml
########################################################################
# sp.pem security certificate to be used with Archive Center.
# You can use the Archive Center cert-tool to generate your own
# certificate and place it in the chart directory. The filename is
# specified in the values.yaml file.
########################################################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: otcs-archive-cert-configmap
  labels:
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
data:
  sp.pem: |
    -----BEGIN PRIVATE KEY-----
    MIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQDNKEUEjozAY679
    icSoEj4RPLIJtdJt+WGQ4iyRnIHaBealWOXiBZrI9YKBnZCo032nnSWOcb15BXQ0
    CKCPIhpuf0kEnkEmiLemYn2WHn9DTBBvW6e5TchgtGRDYxHP7QAxUJg/zmViePc9
    9LtCZW9WQWHYjLd3vdqWk+/2Vd6QRd6474GZtqgN5APKiGS1ahGJlm84/8VHjKi1
    R/PdJS4QLapV50AVD2uGVrJ7+06T0S9RrWfqwd1t7hQ9WJkx9qtjwqmV3XPOqiHo
    NB6Yxr040l9M9EeamS3uIB2+BmXQytjFb3l9MpOPvbSUsv6kyTGuvd0FXeBKk9VZ
    bWpWi4GZAgMBAAECggEAMex2vyEhRz/6uV/pJy0pRXCLsqk4R+LDx0oCpnx7bN66
    vcngRxwuCnEUDQ6WwT6V+U/Yb81l2illmbPvvmUCIZl/30vTdtkWN7sH7JwHRA0i
    gra/Hey7siyzqWJWV07JGTcPlZdYPJpLMBx55TJh4Y+Pi+7SRqVAqBvf7QYAXwLx
    mEc9vz+HU68QaKVcp7UMFoFeqgJEPalVr6tSeJLAm/7PCqvIGYlYoTGNIg/Hf5RA
    7Is9wNFMdyVM1nRDbPGrw8p8bTnlwTwUyQ45SC3fTG0z7iVShmoHJR3vJcsyjsSY
    TWEUj6ZkTGUPzBQnPeBsECJgHUZg11Nb1F2SphK4AQKBgQDPtcFJD2u0/CjUuwR6
    gYN//4X18c9PZFxH96xyvyJkEHd9gAReo2pYn44pPWKHr05MXjJJXFKBtTRXkU7T
    6Mw09a7S2vDEu3Nro6cndQw/JVCYElBd15oyZ3G9hgRd02/8SPXQtDQIDWEjgZkT
    6pPsn0BkQE8/0IYgmzQe5laVwQKBgQD82pZVtxcHDQFtOCGGufDozlvmcVwFpt8q
    FTxw8DXhU6RGwIYN+8x2k6mM2K7W9IDS4tkl8H8yfhMdoY3yNmY6wbSMs8KUUGAH
    qoepqlLNyVZ+8Me7FhK72EXnclYCsWjfqjvcAw5G476LyovVgYRobjkV5N1YR2PC
    XBcmx+TR2QKBgQCdTSh0DBmlltHVSUy6+hp8dScee2Jk3byFRCx1OgrxfQcBJFIq
    2ddQBoXC9ZoI59qEO1IZ/LD/Shu5tXHdShBcizM6vFRaqRtgCTAt0ZbUu42tnTD/
    4KgGRBD/Vt83r0i/5wFCbTZ6YqeOHDexvZUJPhGl2o4p5eGuD9wJCqfIAQKBgQCk
    4SisxhIW/+0ROkvqXW9xb7bPgtX9vX3CJEzgXFLWFsOFe18u2SXPoKQr+tOvyYoD
    efcdXUCkPT/bz5APBFgPMma4ZTOZoPutpA6InU8Xb5WeewXSwib/JJ0Yuh7J7MO1
    LX2RDtENes6yuyYJ2EXuDwncc/u95/duMrzKBgj4qQKBgQChz3UlqX/bS4l0bQKZ
    0H9pQRW8NofFyoEckJ928BH5YDsI/LTNvKCDCyAJqgQnwX+Wu5GTkp/iKIskcoYs
    cvZVxvCcI6R5P8BRJLc2Y67Ka4A27Y31Q12dv0ditxGd1DkLxxUip4V9AAjKR1qa
    XvNVSlWjFe/HwyBCA9gXjplf2Q==
    -----END PRIVATE KEY-----
    -----BEGIN CERTIFICATE-----
    MIIEdzCCAt+gAwIBAgIRANoZkt8+FSzcCdMI0meFNJMwDQYJKoZIhvcNAQELBQAw
    gY8xHjAcBgNVBAoTFW1rY2VydCBkZXZlbG9wbWVudCBDQTEyMDAGA1UECwwpRUNN
    LUhBTktSXO2VnOq4sOuhnEBFQ00taGFua3IgKEtlZXJvIEhhbikxOTA3BgNVBAMM
    MG1rY2VydCBFQ00tSEFOS1Jc7ZWc6riw66GcQEVDTS1oYW5rciAoS2Vlcm8gSGFu
    KTAeFw0yNTA4MjIwMDIzMzBaFw0yNzExMjIwMDIzMzBaMF0xJzAlBgNVBAoTHm1r
    Y2VydCBkZXZlbG9wbWVudCBjZXJ0aWZpY2F0ZTEyMDAGA1UECwwpRUNNLUhBTktS
    XO2VnOq4sOuhnEBFQ00taGFua3IgKEtlZXJvIEhhbikwggEiMA0GCSqGSIb3DQEB
    AQUAA4IBDwAwggEKAoIBAQDNKEUEjozAY679icSoEj4RPLIJtdJt+WGQ4iyRnIHa
    BealWOXiBZrI9YKBnZCo032nnSWOcb15BXQ0CKCPIhpuf0kEnkEmiLemYn2WHn9D
    TBBvW6e5TchgtGRDYxHP7QAxUJg/zmViePc99LtCZW9WQWHYjLd3vdqWk+/2Vd6Q
    Rd6474GZtqgN5APKiGS1ahGJlm84/8VHjKi1R/PdJS4QLapV50AVD2uGVrJ7+06T
    0S9RrWfqwd1t7hQ9WJkx9qtjwqmV3XPOqiHoNB6Yxr040l9M9EeamS3uIB2+BmXQ
    ytjFb3l9MpOPvbSUsv6kyTGuvd0FXeBKk9VZbWpWi4GZAgMBAAGjfzB9MA4GA1Ud
    DwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAfBgNVHSMEGDAWgBS8DwrY
    5M2LaDE7kl8qF8qxE5PfgDA1BgNVHREELjAsggxteXVidW50dTYuaHaCDioubXl1
    YnVudHU2Lmh2ggxteXVidW50dTYtaHYwDQYJKoZIhvcNAQELBQADggGBAGW7rmJI
    TzsBgXj9rTpcdHcSO0gVNQctBD44eWkmtv+xKS2PmWmo4zDNT92KgjrysL6FUuW/
    iIndmmn0Ue4xX2iY+L7iVubDsDsw4OqPpJnsSO1wZSThZZurDw4id7Xc4nrYI62O
    N9UXTn2ICCSi8cDZZb99HmBAeMTAfoE6+/Z15b3/BBrTX52JAN2gOxv8czCv+Iur
    s8pGN4f3Nz2iPYL6L/7yUEnrXOp25IU/2mQgIMk2HAXRNnNUeSdlx+vC3bmLKj1x
    zYm1ew39a2whvxuZmsrTzOpR+Cq3azFelTjwVFzhMIBZkKR7IX/+qDFufZ+0xfQo
    4L35TlWvVzGifRAjix7ZATk9F8fSXn57NJbZdxKmoTkNt2XulONcc+xcxw4uvOrZ
    djMHOOzmhPCsMrfYPphJ8dHoj1SmLXkRcY+A6md2B48LP+ReN5Gi8N3+JsZKohiP
    L09GymSU+x9b7NQkJeKSNeGazGqMvSB5nRy/H7rEnnCrwMlPYHj0juCNJQ==
    -----END CERTIFICATE-----
---
# Source: otxecm/charts/otds/charts/otdsws/templates/otds-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otdsws-configmap
  labels:
    app.kubernetes.io/name: otdsws
    helm.sh/chart: otdsws-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
data:
  OTDS_OTDSWS_CONTAINER: "true"
  OTDS_JAKARTA_PERSISTENCE_JDBC_URL: "jdbc:postgresql://192.168.100.216:5432/otdsdb"
  SAPSYSTEMCLIENT: "001"
  SAPSYSTEMNAME: OTX
  TZ: Asia/Seoul
  OTDS_DIRECTORY_BOOTSTRAP_ELECTMASTER: "true"
  OTDS_REPO_ALLOWDUPLICATEUSERS: "true"
  OTDS_REPO_TENANTIMPORTEXPORTPATH: "/opt/otdsdata/tenantdata"
  OTDS_LOGTOFILES: "false"
  OTDS_LOGFILES_PATH: "/opt/tomcat/logs"
  ENABLE_ACCESSLOG_FILES: "false"
  ENABLE_ACCESSLOG_STDOUT: "true"
---
# Source: otxecm/charts/otiv/charts/amqp/templates/configuration.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-amqp-config
data:
  enabled_plugins: |-
    [rabbitmq_federation, rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_prometheus].
  rabbitmq.conf: |-
    default_user=$(IV_AMQP_USER)
    default_pass=$(IV_AMQP)
    cluster_formation.k8s.service_name = otiv-amqp
    loopback_users.guest = false
    listeners.tcp.default = 5672
    log.file = false
    log.console = true
    cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s
    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
    cluster_formation.k8s.address_type = hostname
    cluster_formation.node_cleanup.only_log_warning = true
    consumer_timeout = 7200000



  advanced.config: |-
    [{rabbit, [ { default_consumer_prefetch, {false, 1}} ]}].
---
# Source: otxecm/charts/otiv/charts/asset/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
    name: otiv-asset-configmap
data:
    ARTIFACT_VOLUMES_ROOT: /var/mkondo
    ACCESS_MODEL: getPublication
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    CLUSTER_DISCOVERY: kubernetes
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    ENABLE_OAUTH: 'true'
    EVENT_LOOP_POOL_SIZE: '4'
    LOG_OUT: stdout
    DISCOVERY_REGISTER_POLICY: name
    DISCOVERY_REGISTER_POLICY_NAME: otiv-asset
    PEER_REST_PORT: '80'
    PORT: '9093'
    PUBLICATION_SERVICE_ORIGIN: http://otiv-publication:80
    TZ: Asia/Seoul
    VERTX_CLUSTER_NETWORK_PORT: '5701'
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/config/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-config-configmap
data:
    AUTHORITY: http://otiv-config:80
    CLUSTER_DISCOVERY: kubernetes
    DB_ADM_PWD_KEY: OTIV_DB_ADMIN_PASSWORD
    PITHOS_PWD_KEY: OTIV_DB_PASSWORD
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    ENABLE_OAUTH: 'true'    
    EVENT_LOOP_POOL_SIZE: '6'
    LOG_OUT: stdout
    DISCOVERY_REGISTER_POLICY: name
    DISCOVERY_REGISTER_POLICY_NAME: otiv-config
    PEER_REST_PORT: '80'
    PORT: '9678'
    PITHOS_PROVIDER: postgresql
    PITHOS_HOST: 192.168.100.216
    PITHOS_PORT: '5432'
    PITHOS_DB: otiv
    DB_ADMIN_USER: postgres
    PITHOS_USER: otiv
    PITHOS_ADMIN_DB: postgres
    PITHOS_USE_SSL: 'false'
    PITHOS_SSL_MODE: 'prefer'
    SOTERIA_PROVIDER: otds
    PITHOS_KEYSTORE_TYPE: 'JKS'
    TZ: Asia/Seoul
    VERTX_CLUSTER_NETWORK_PORT: '5701'
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/highlight/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-highlight-configmap
data:
    AUTH_TOKEN_URL: http://otds/otdsws/oauth2/token
    DOC_ROOT: 'https://developer.opentext.com/products_services/aa064dbd-8954-4d0f-8892-65fe2de124bb'
    LOG_LEVEL: 'info'
    ARTIFACT_BASE_URL_PUBLIC: https://otiv-asset.myubuntu6.hv/artifacts
    ARTIFACT_BASE_URL: http://otiv-asset/artifacts
    AUTH_CLIENT_ID: iv-highlight
    PUBLICATION_AUTHORITY: http://otiv-publication:80
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    HIGHLIGHT_CLIENT_SECRET_KEY: OTIV_HIGHLIGHT_CLIENT_SECRET
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    DISABLE_FORWARDING: 'true'
    OTDS_CERT_UPDATE_INTERVAL: '1440'
    PORT: '3000'
    SEARCH_AUTHORITY: https://otiv-highlight.myubuntu6.hv
    TZ: Asia/Seoul
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/markup/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-markup-configmap
data:
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    DB_ADM_PWD_KEY: OTIV_DB_ADMIN_PASSWORD
    PITHOS_PWD_KEY: OTIV_DB_PASSWORD
    MARKUP_DB_PWD_KEY: OTIV_DB_PASSWORD
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    PITHOS_PROVIDER: postgresql
    DB_PROVIDER: postgresql
    DB_HOST: 192.168.100.216
    DB_PORT: '5432'
    DB_NAME: otiv
    PITHOS_ADMIN_DB: postgres
    DB_USER: otiv
    DB_ADMIN_USER: postgres
    DB_USE_SSL: 'false'
    DB_MAX_POOL_SIZE: '10'
    ENABLE_ROLE_BASED_ACCESS_CONTROL: 'true'
    DOC_ROOT: 'https://developer.opentext.com/products_services/aa064dbd-8954-4d0f-8892-65fe2de124bb'
    DISABLE_FORWARDING: 'true'
    LOG_LEVEL: 'info'
    MARKUP_AUTHORITY: https://otiv-markup.myubuntu6.hv
    NODE_ENV: production
    OTDS_CERT_UPDATE_INTERVAL: '1440'
    PORT: '3000'
    TZ: Asia/Seoul
    VERTX_CLUSTER_NETWORK_PORT: '5701'
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/publication/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-publication-configmap
data:
    ACCESS_MODEL: headCheckSource
    ACCESS_CHECK_TIMEOUT_SECONDS: '3'
    AJIRA_PORT: '5672'
    AJIRA_USE_SSL: 'false'
    AJIRA_HOST: otiv-amqp
    AJIRA_USER: user
    AJIRA_VHOST: /
    API_DOC_ROOT_URL: 'https://developer.opentext.com/apis/69f18c6b-0b58-4509-8117-6bf022fd2e44/aa064dbd-8954-4d0f-8892-65fe2de124bb/12bc3ec7-22df-42d4-8f27-d5c4ccb9dd0e'
    AUTHORITY: https://otiv-publication.myubuntu6.hv
    CLUSTER_DISCOVERY: kubernetes
    DB_ADM_PWD_KEY: OTIV_DB_ADMIN_PASSWORD
    PITHOS_PWD_KEY: OTIV_DB_PASSWORD
    PUBLICATION_CLIENT_SECRET_KEY: OTIV_PUBLICATION_CLIENT_SECRET
    MONITORING_CLIENT_SECRET_KEY: OTIV_MONITOR_CLIENT_SECRET
    AJIRA_PWD_KEY: rabbitmq-password
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    ENABLE_ACCESS_CACHE: 'true'
    ENABLE_FORWARDING: 'false'
    STICKY_FORWARDING_PROTOCOL: https
    ENABLE_OAUTH: 'true'
    EVENT_LOOP_POOL_SIZE: '8'
    LOG_OUT: stdout
    DISCOVERY_REGISTER_POLICY: name
    DISCOVERY_REGISTER_POLICY_NAME: otiv-publication
    AUTH_CLIENT_ID: iv-publication
    MONITORING_AUTH_CLIENT_ID: iv-monitoring
    MKONDO_BLOB_BASE_URL: https://otiv-asset.myubuntu6.hv/artifacts
    MKONDO_BLOB_ROOTS: /var/mkondo/fs-0
    MKONDO_STORAGE_DISABLED: 'false'
    PEER_REST_PORT: '80'
    PORT: '9091'
    PITHOS_PROVIDER: postgresql
    PITHOS_HOST: 192.168.100.216
    PITHOS_PORT: '5432'
    PITHOS_DB: otiv
    DB_ADMIN_USER: postgres
    PITHOS_ADMIN_DB: postgres
    PITHOS_USER: otiv
    PITHOS_USE_SSL: 'false'
    PITHOS_SSL_MODE: 'prefer'
    PITHOS_KEYSTORE_TYPE: 'JKS'
    SOTERIA_PROVIDER: otds
    TZ: Asia/Seoul
    TRUSTED_SOURCE_ORIGINS: http://otcs-frontend
    VERTX_CLUSTER_NETWORK_PORT: '5701'
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/publisher/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-publisher-configmap
data:
    AJIRA_PORT: '5672'
    AJIRA_USE_SSL: 'false'
    AJIRA_HOST: otiv-amqp
    AJIRA_USER: user
    AJIRA_VHOST: /
    ARTIFACT_DELIVERY_PROFILE: mkondo
    METRICS_PROVIDER: dropwizard
    MKONDO_BLOB_BASE_URL: https://otiv-asset.myubuntu6.hv/artifacts
    MARKUP_SERVICE_ORIGIN: http://otiv-markup:80
    MKONDO_BLOB_ROOTS: /var/mkondo/fs-0
    MKONDO_STORAGE_DISABLED: 'false'
    CLUSTER_DISCOVERY: kubernetes
    COUNTER: '1'
    ENABLE_OAUTH: 'true'
    EVENT_LOOP_POOL_SIZE: '8'
    LOG_OUT: stdout
    WRITE_MARKUPS: 'true'
    PITHOS_HOST: 192.168.100.216
    PITHOS_PROVIDER: postgresql
    PITHOS_PORT: '5432'
    PITHOS_DB: otiv
    AUTH_CLIENT_ID: iv-publisher
    DB_ADMIN_USER: postgres
    PITHOS_ADMIN_DB: postgres
    PITHOS_USER: otiv
    PITHOS_USE_SSL: 'false'
    PITHOS_SSL_MODE: 'prefer'
    INTERNAL_REST_PORT: '9092'
    PITHOS_KEYSTORE_TYPE: 'JKS'
    SOTERIA_PROVIDER: otds
    TZ: Asia/Seoul
    TRUSTED_SOURCE_ORIGINS: http://otcs-frontend
    DB_ADM_PWD_KEY: OTIV_DB_ADMIN_PASSWORD
    PITHOS_PWD_KEY: OTIV_DB_PASSWORD
    PUBLISHER_CLIENT_SECRET_KEY: OTIV_PUBLISHER_CLIENT_SECRET
    AJIRA_PWD_KEY: rabbitmq-password
    VERTX_CLUSTER_NETWORK_PORT: '5701'
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/charts/viewer/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-viewer-configmap
data:
    CORS_ADDITIONAL_HEADERS_LIST: ''
    COUNTER: '1'
    ENFORCE_CORS_ORIGINS: 'false'
    ENFORCE_FORWARDED_HOSTS: 'false'
    DOC_ROOT: 'https://developer.opentext.com/apis/69f18c6b-0b58-4509-8117-6bf022fd2e44/aa064dbd-8954-4d0f-8892-65fe2de124bb/08f4af59-5119-4894-9efc-07941c67c2c1'
    DISABLE_FORWARDING: 'true'
    LOG_LEVEL: 'info'
    OTDS_CERT_UPDATE_INTERVAL: '1440'
    PORT: '3000'
    TZ: Asia/Seoul
    VIEWER_AUTHORITY: https://otiv-viewer.myubuntu6.hv
    __VERSION__: '25.3.0'
---
# Source: otxecm/charts/otiv/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otiv-configmap
data:
    OTCS_URL: http://otcs-frontend
    CS_URI_PATH: '/cs/cs'
    IS_INSTALL: 'True'
    RESOURCE_GUID:  '4b9fb208-5a47-4585-97bd-7f38b4cc3d12'
    XECM_CHART: 'True'
    KUB_NAMESPACE: default
    OTDS_ORIGIN: http://otds/otdsws
    REF_NM: 'otxecm-default-secrets'
    ACC_KY: ADMIN_USER_PASSWORD
    RESOURCE_KEY: resource
    RUNTIME_ENVIRONMENT: cfcr-iv
   # Provides default secret env vars for transforomation pods; overwritten by some pods
    SECRET_MANAGER_TYPE: k8s
    SECRET_NAME: 'otxecm-default-secrets'
---
# Source: otxecm/charts/otcs/templates/otcs-pvc.yaml
########################################################################
# Object importer persistent volume claim for OpenText Content Server
# There is a volume 
# 'otcs-sftp-volume' in the otcs StatefulSet.
# otcs-statefulsets.yaml
########################################################################
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sftp-volume
  labels:
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: microk8s-hostpath
  resources:
    requests:
      storage: 1Gi
---
# Source: otxecm/charts/otcs/templates/otxecm-ctrl-serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: otxecm-ctrl
---
# Source: otxecm/charts/otds/charts/otdsws/templates/otds-roles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: otdsws-role
  labels:
    app.kubernetes.io/name: otdsws
    helm.sh/chart: otdsws-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
---
# Source: otxecm/charts/otiv/charts/amqp/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-amqp
  labels:
    app: rabbitmq
    chart: rabbitmq-1
    release: "xecm-release"
    heritage: "Helm"
rules:
- apiGroups:
    - ""
  resources:
    - endpoints
  verbs:
    - get
    - list
    - watch
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-role
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "create", "patch", "update", "delete"]
- apiGroups: [""]
  resources: ["endpoints"]
  verbs: ["get"]
---
# Source: otxecm/templates/otxecm-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: otcs-automation-role
  labels:
    app.kubernetes.io/name: otxecm
    helm.sh/chart: otxecm-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["apps"] # "" indicates the core API group
  resources: ["statefulsets","statefulsets/scale","statefulsets/status"]
  verbs: ["get", "watch", "list"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "watch", "list"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "patch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["delete"]
---
# Source: otxecm/charts/otcs/templates/otxecm-ctrl-serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otxecm-ctrl
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otxecm-ctrl
subjects:
- kind: ServiceAccount
  name: otxecm-ctrl
  namespace: master
---
# Source: otxecm/charts/otds/charts/otdsws/templates/otds-roles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otdsws-rbac
  labels:
    app.kubernetes.io/name: otdsws
    helm.sh/chart: otdsws-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otdsws-role
subjects:
- kind: ServiceAccount
  name: otxecm-sa
---
# Source: otxecm/charts/otiv/charts/amqp/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: otiv-amqp
  labels:
    app: rabbitmq
    chart: rabbitmq-1
    release: "xecm-release"
    heritage: "Helm"
subjects:
- kind: ServiceAccount
  name: otiv-amqp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-amqp
---
# Source: otxecm/charts/otiv/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: otiv-rbac
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otiv-role
subjects:
- kind: ServiceAccount
  name: otxecm-sa
---
# Source: otxecm/templates/otxecm-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/name: otxecm
    helm.sh/chart: otxecm-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/managed-by: Helm
  name: otcs-automation-rolebinding
  namespace: default  
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: otcs-automation-role
subjects:
- kind: ServiceAccount
  name: otxecm-sa
  namespace: default
---
# Source: otxecm/charts/otac/templates/otac-services.yaml
########################################################################
# OpenText Archive Center Kubernetes Service
########################################################################
kind: Service
apiVersion: v1
metadata:
  name: otac-0
  labels:
    app.kubernetes.io/name: otac
    helm.sh/chart: otac-24.4.3
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: NodePort
  ports:
  - name: otac
    protocol: TCP
    port: 8080
    targetPort: 8080
  selector:
    app.kubernetes.io/component: otac
    app.kubernetes.io/instance: xecm-release
---
# Source: otxecm/charts/otcs/templates/otcs-services.yaml
########################################################################
# OpenText Content Server (FRONTEND SERVER) Kubernetes Service
########################################################################
kind: Service
apiVersion: v1
metadata:
  name: otcs-frontend
  labels:
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: NodePort
  ports:
    - name: otcs-web
      port: 80
      targetPort: 8080
    - name: otcs-api
      port: 2099
      targetPort: 2099
  selector:
    app.kubernetes.io/component: otcs-frontend
    app.kubernetes.io/instance: xecm-release
---
# Source: otxecm/charts/otcs/templates/otcs-services.yaml
########################################################################
# OpenText Content Server (ADMIN SERVER) Kubernetes Service
# NOT exposed outside the Kubernetes cluster
########################################################################
kind: Service
apiVersion: v1
metadata:
  name: otcs-admin-0
  labels:
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  # Configure the service to be headless
  clusterIP: None
  ports:
  - name: otcs-admin
    port: 80
    targetPort: 8080
  - name: otcs-tomcat
    port: 8080
    targetPort: 8080
  - name: otcs-search
    port: 5858
    targetPort: 5858
  selector:
    app.kubernetes.io/component: otcs-admin
    app.kubernetes.io/instance: xecm-release
  publishNotReadyAddresses: true
---
# Source: otxecm/charts/otcs/templates/otcs-services.yaml
#####################################################################
# OpenText Content Server (BACKEND SEARCH) Kubernetes Service
# NOT exposed outside the Kubernetes cluster
#####################################################################
kind: Service
apiVersion: v1
metadata:
  name: otcs-backend-search
  labels:
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  # Configure the service to be headless
  clusterIP: None
  ports:
  - name: otcs-backend-search
    port: 80
    targetPort: 8080
  - name: otcs-backend-tomcat
    port: 8080
    targetPort: 8080
  - name: otcs-backend-search-admin
    port: 5858
    targetPort: 5858
  selector:
    app.kubernetes.io/component: otcs-backend-search
    app.kubernetes.io/instance: xecm-release
  publishNotReadyAddresses: true
---
# Source: otxecm/charts/otcs/templates/otxecm-ctrl-service.yaml
kind: Service
apiVersion: v1
metadata:
  name:  otxecm-ctrl
spec:
  selector:
    app:  otxecm-ctrl
  type:  ClusterIP
  ports:
  - name:  http
    port:  8000
    targetPort:  8000
---
# Source: otxecm/charts/otds/charts/otdsws/templates/otds-services.yaml
########################################################################
# OpenText Directory Services (OTDS) Kubernetes Service
########################################################################
kind: Service
apiVersion: v1
metadata:
  name: otds
  labels:
    app.kubernetes.io/name: otdsws
    helm.sh/chart: otdsws-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: NodePort
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 8080
  selector:
    app.kubernetes.io/component: otdsws
    app.kubernetes.io/instance: xecm-release
---
# Source: otxecm/charts/otiv/charts/amqp/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-amqp
  labels:
    app: rabbitmq
    chart: rabbitmq-1
    release: "xecm-release"
    heritage: "Helm"
spec:
  clusterIP: None
  ports:
  - port: 15672
    targetPort: 15672
    name: discovery
  - port: 5672
    targetPort: 5672
    name: amqp
  - port: 15692
    targetPort: 15692
    name: metrics
  selector:
    app: otiv-amqp
    release: "xecm-release"
---
# Source: otxecm/charts/otiv/charts/asset/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-asset
  labels:
    app.kubernetes.io/name: asset
    helm.sh/chart: asset-0.1.0
    app.kubernetes.io/instance: otiv-asset
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 9093
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-asset
    app: otiv-asset
---
# Source: otxecm/charts/otiv/charts/config/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-config
  labels:
    app.kubernetes.io/name: config
    helm.sh/chart: config-0.1.0
    app.kubernetes.io/instance: otiv-config
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 9678
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-config
    app: otiv-config
---
# Source: otxecm/charts/otiv/charts/highlight/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-highlight
  labels:
    app.kubernetes.io/name: highlight
    helm.sh/chart: highlight-0.1.0
    app.kubernetes.io/instance: otiv-highlight
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3000
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-highlight
    app: otiv-highlight
---
# Source: otxecm/charts/otiv/charts/markup/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-markup
  labels:
    app.kubernetes.io/name: markup
    helm.sh/chart: markup-0.1.0
    app.kubernetes.io/instance: otiv-markup
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3000
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-markup
    app: otiv-markup
---
# Source: otxecm/charts/otiv/charts/publication/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-publication
  labels:
    app.kubernetes.io/name: publication
    helm.sh/chart: publication-0.1.0
    app.kubernetes.io/instance: otiv-publication
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 9091
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-publication
    app: otiv-publication
---
# Source: otxecm/charts/otiv/charts/publisher/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-publisher
  labels:
    app.kubernetes.io/name: publisher
    helm.sh/chart: publisher-0.1.0
    app.kubernetes.io/instance: otiv-publisher
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 9092
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-publisher
    app: otiv-publisher
---
# Source: otxecm/charts/otiv/charts/viewer/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otiv-viewer
  labels:
    app.kubernetes.io/name: viewer
    helm.sh/chart: viewer-0.1.0
    app.kubernetes.io/instance: otiv-viewer
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3000
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: otiv-viewer
    app: otiv-viewer
---
# Source: otxecm/charts/otiv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: cvt-hazel
  labels:
    app.kubernetes.io/name: otiv
    app.kubernetes.io/instance: hazel-otiv-svc
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - port: 5701
      protocol: TCP
      appProtocol: tcp
      name: hazelcast
  clusterIP: None
  selector:
      hazelcast: cvt
---
# Source: otxecm/charts/otcs/templates/otxecm-ctrl-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name:  otxecm-ctrl
  labels:
    app:  otxecm-ctrl
spec:
  selector:
    matchLabels:
      app: otxecm-ctrl
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app:  otxecm-ctrl
    spec:
      automountServiceAccountToken: true
      securityContext:
        fsGroup: 1001
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
      containers:
      - name:  otxecm-ctrl
        image: registry.opentext.com/otxecm-ctrl:25.3.0
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 10m
            memory: 100Mi
          limits:
            cpu: 500m
            memory: 256Mi
        livenessProbe:
          tcpSocket:
            port: 8000
          initialDelaySeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 5
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
          periodSeconds: 10
        ports:
        - containerPort:  8000
          name:  otxecm-ctrl
      restartPolicy: Always
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otds/charts/otdsws/templates/otds-deployment.yaml
########################################################################
# OpenText Directory Services (OTDS)
########################################################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: otdsws
  labels:
    app.kubernetes.io/component: otdsws
    app.kubernetes.io/name: otdsws
    helm.sh/chart: otdsws-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: otdsws
      app.kubernetes.io/instance: xecm-release
      
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/component: otdsws
        app.kubernetes.io/instance: xecm-release
        
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
        runAsNonRoot: true
      initContainers:
      volumes:
        - name: otdsws-temp-volume
          emptyDir:
            sizeLimit: 128Mi
        - name: otdsws-logs-volume
          emptyDir:
            sizeLimit: 1024Mi
        - name: otdsws-work-volume
          emptyDir:
            sizeLimit: 128Mi
      serviceAccountName: otxecm-sa
      containers:
      - name: otdsws
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
        envFrom:
        - configMapRef:
            name: otdsws-configmap
        env:
        - name: OTDS_K8S_SECRET_NAME
          value: otxecm-default-secrets
        volumeMounts:
          - name: otdsws-temp-volume
            mountPath: /opt/tomcat/temp
          - name: otdsws-logs-volume
            mountPath: /opt/tomcat/logs
          - name: otdsws-work-volume
            mountPath: /opt/tomcat/work
        readinessProbe:
          httpGet:
            path: /otdsws/health/readiness
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /otdsws/health/liveness
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
        startupProbe:
          httpGet:
            path: /otdsws/health/liveness
            port: 8080
          periodSeconds: 10
          failureThreshold: 24
        image: registry.opentext.com/otds-server:25.3.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
      hostname: 
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otiv/charts/asset/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-asset
  labels:
    app.kubernetes.io/name: asset
    helm.sh/chart: asset-0.1.0
    app.kubernetes.io/instance: otiv-asset
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-asset
      app.kubernetes.io/name: asset
      app.kubernetes.io/instance: otiv-asset
      hazel: brava
  template:
    metadata:
      annotations:
        checksum/config: 3ffd7cde3695b5a97020dada06949e94e7803746dad43d1593af5d34f01513d2
      labels:
        app: otiv-asset
        app.kubernetes.io/name: asset
        app.kubernetes.io/instance: otiv-asset
        hazel: brava
        hazelcast: cvt
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-asset
          image: registry.opentext.com/otiv-asset:25.3.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["bash", "/app/bin/shutdown"]
          securityContext:
            allowPrivilegeEscalation: false
          ports:
          - name: hazelcast
            containerPort: 5701
          - name: http
            containerPort: 9093
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /asset/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 3
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /asset/api/v1/health/ready
              port: http
            initialDelaySeconds: 10
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /asset/api/v1/health/live
              port: http
            initialDelaySeconds:  35
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          - name: VERTX_CLUSTER_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-asset-configmap
          volumeMounts:
            - mountPath: /var/mkondo/fs-0
              name: bas-data
      imagePullSecrets:
      - name: regcred
      
      volumes:
        - name: bas-data
          persistentVolumeClaim:
            claimName: otiv-bas
---
# Source: otxecm/charts/otiv/charts/config/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-config
  labels:
    app.kubernetes.io/name: config
    helm.sh/chart: config-0.1.0
    app.kubernetes.io/instance: otiv-config
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-config
      app.kubernetes.io/name: config
      app.kubernetes.io/instance: otiv-config
      hazel: brava
  template:
    metadata:
      annotations:
        checksum/config: a8dda57efae063a99a92be908d87a0b52b9821d3c790e2f5758f1b740256b56c
      labels:
        app: otiv-config
        app.kubernetes.io/name: config
        app.kubernetes.io/instance: otiv-config
        hazel: brava
        hazelcast: cvt
    spec:
      volumes:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-config
          image: registry.opentext.com/otiv-config:25.3.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["bash", "/app/bin/shutdown"]
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          ports:
          - name: hazelcast
            containerPort: 5701
            protocol: TCP
          - name: http
            containerPort: 9678
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /config/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 3
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /config/api/v1/health/ready
              port: http
            initialDelaySeconds: 10
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /config/api/v1/health/live
              port: http
            initialDelaySeconds:  45
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          - name: VERTX_CLUSTER_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-config-configmap
        
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otiv/charts/highlight/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-highlight
  labels:
    app.kubernetes.io/name: highlight
    helm.sh/chart: highlight-0.1.0
    app.kubernetes.io/instance: otiv-highlight
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-highlight
      app.kubernetes.io/name: highlight
      app.kubernetes.io/instance: otiv-highlight
  template:
    metadata:
      annotations:
        checksum/config: a4ed3148cc4ea53e837a561000d9226e2523c341405b4aef58202cebc883b6b1
      labels:
        app: otiv-highlight
        app.kubernetes.io/name: highlight
        app.kubernetes.io/instance: otiv-highlight
    spec:
      volumes:
      securityContext:
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-highlight
          image: registry.opentext.com/otiv-highlight:25.3.0
          imagePullPolicy: IfNotPresent
          volumeMounts:
          securityContext:
            allowPrivilegeEscalation: false
          ports:
          - name: http
            containerPort: 3000
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /search/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /search/api/v1/health/ready
              port: http
            initialDelaySeconds: 5
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /search/api/v1/health/live
              port: http
            initialDelaySeconds:  35
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          
          
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-highlight-configmap
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otiv/charts/markup/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-markup
  labels:
    app.kubernetes.io/name: markup
    helm.sh/chart: markup-0.1.0
    app.kubernetes.io/instance: otiv-markup
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-markup
      app.kubernetes.io/name: markup
      app.kubernetes.io/instance: otiv-markup
  template:
    metadata:
      annotations:
        checksum/config: 0913f0a6fddbc5e95f1c117a9876195a3e9c73bf8a59ba90eadb0aaa0f707249
      labels:
        app: otiv-markup
        app.kubernetes.io/name: markup
        app.kubernetes.io/instance: otiv-markup
    spec:
      volumes:
      securityContext:
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-markup
          image: registry.opentext.com/otiv-markup:25.3.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          ports:
          - name: http
            containerPort: 3000
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /markup/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /markup/api/v1/health/ready
              port: http
            initialDelaySeconds: 5
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /markup/api/v1/health/live
              port: http
            initialDelaySeconds:  45
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-markup-configmap
        
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otiv/charts/publication/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-publication
  labels:
    app.kubernetes.io/name: publication
    helm.sh/chart: publication-0.1.0
    app.kubernetes.io/instance: otiv-publication
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-publication
      app.kubernetes.io/name: publication
      app.kubernetes.io/instance: otiv-publication
      hazel: brava
  template:
    metadata:
      annotations:
        checksum/config: 1fa5e7a9ad5ca7a1938b9534cadf8bfb6d23fb542e832fabfb057d0921e99e6b
      labels:
        app: otiv-publication
        app.kubernetes.io/name: publication
        app.kubernetes.io/instance: otiv-publication
        hazel: brava
        hazelcast: cvt
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-publication
          image: registry.opentext.com/otiv-publication:25.3.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["bash", "/app/bin/shutdown"]
          securityContext:
            allowPrivilegeEscalation: false
          ports:
          - name: hazelcast
            containerPort: 5701
            protocol: TCP
          - name: http
            containerPort: 9091
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /publication/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 3
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /publication/api/v1/health/ready
              port: http
            initialDelaySeconds: 10
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /publication/api/v1/health/live
              port: http
            initialDelaySeconds:  45
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          - name: VERTX_CLUSTER_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          
          
          
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-publication-configmap
          volumeMounts:
            - mountPath: /var/mkondo/fs-0
              name: bas-data
        
      imagePullSecrets:
      - name: regcred
      
      volumes:  
        - name: bas-data
          persistentVolumeClaim:
            claimName: otiv-bas
---
# Source: otxecm/charts/otiv/charts/publisher/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-publisher
  labels:
    app.kubernetes.io/name: publisher
    helm.sh/chart: publisher-0.1.0
    app.kubernetes.io/instance: otiv-publisher
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-publisher
      app.kubernetes.io/name: publisher
      app.kubernetes.io/instance: otiv-publisher
      hazel: brava
  template:
    metadata:
      annotations:
        checksum/config: 072f590dd743f77295328ddd0344b75f227aefdffaa61c353d734329aaaf86a1
      labels:
        app: otiv-publisher
        app.kubernetes.io/name: publisher
        app.kubernetes.io/instance: otiv-publisher
        hazel: brava
        hazelcast: cvt
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      serviceAccountName: otxecm-sa
      terminationGracePeriodSeconds: 60
      containers:
        - name: otiv-publisher
          image: registry.opentext.com/otiv-publisher:25.3.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command: ["bash", "/app/bin/shutdown"]
          securityContext:
            allowPrivilegeEscalation: false
          ports:
          - name: hazelcast
            containerPort: 5701
            protocol: TCP
          - name: http
            containerPort: 9092
            protocol: TCP
          env:
          
          
          
          - name: VERTX_CLUSTER_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-publisher-configmap
          livenessProbe:
            httpGet:
              path: /publisher/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 10
            periodSeconds: 30
            failureThreshold: 4
          readinessProbe:
            httpGet:
              path: /publisher/api/v1/health/ready
              port: http
            initialDelaySeconds: 10
            timeoutSeconds: 2
            periodSeconds: 60
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /publisher/api/v1/health/live
              port: http
            initialDelaySeconds:  60
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          volumeMounts:
            - mountPath: /var/mkondo/fs-0
              name: bas-data
        
      imagePullSecrets:
      - name: regcred
      
      volumes:
        - name: bas-data
          persistentVolumeClaim:
            claimName: otiv-bas
---
# Source: otxecm/charts/otiv/charts/viewer/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otiv-viewer
  labels:
    app.kubernetes.io/name: viewer
    helm.sh/chart: viewer-0.1.0
    app.kubernetes.io/instance: otiv-viewer
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otiv-viewer
      app.kubernetes.io/name: viewer
      app.kubernetes.io/instance: otiv-viewer
  template:
    metadata:
      annotations:
        checksum/config: e5b5f536af18c0ef96a0dfb49106dd731f6049bb2620ba64d6347d0f4c551737
      labels:
        app: otiv-viewer
        app.kubernetes.io/name: viewer
        app.kubernetes.io/instance: otiv-viewer
    spec:
      volumes:
      securityContext:
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      serviceAccountName: otxecm-sa
      containers:
        - name: otiv-viewer
          image: registry.opentext.com/otiv-viewer:25.3.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:  
          ports:
          - name: http
            containerPort: 3000
            protocol: TCP
          livenessProbe:
            httpGet:
              path: /viewer/api/v1/health/live
              port: http
            initialDelaySeconds:  1800
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /viewer/api/v1/health/ready
              port: http
            initialDelaySeconds: 5
            timeoutSeconds: 2
            periodSeconds: 25
            failureThreshold: 2
          startupProbe:
            httpGet:
              path: /viewer/api/v1/health/live
              port: http
            initialDelaySeconds:  35
            timeoutSeconds: 2
            periodSeconds: 30
            failureThreshold: 80
          env:
          
          envFrom:
          - configMapRef:
              name: otiv-configmap
          - configMapRef:
              name: otiv-viewer-configmap
      imagePullSecrets:
      - name: regcred
---
# Source: otxecm/charts/otac/templates/otac-statefulsets.yaml
########################################################################
# OpenText Archive Center Kuberntes Stateful Sets
########################################################################
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: otac
  labels:
    app.kubernetes.io/component: otac
    app.kubernetes.io/name: otac
    helm.sh/chart: otac-24.4.3
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "0.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  serviceName: otac
  selector:
    matchLabels:
      app.kubernetes.io/component: otac
      app.kubernetes.io/instance: xecm-release
  template:
    metadata:
      labels:
        app.kubernetes.io/component: otac
        app.kubernetes.io/instance: xecm-release
      annotations:
        checksum/config: 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'
    spec:
      priorityClassName: xecm-release-default-1
      securityContext:
        ## The fsGroup field specifies that group ID 1000 is associated
        ## with all Containers in the Pod. Group ID 1000 is also
        ## associated with the mounted volumes and with any files created
        ## in that volume.
        ## This will make volumes be mounted with 1000 group permissions.
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otxecm-sa
      containers:
      - name: otac
        image: registry.opentext.com/otac:24.4.3
        imagePullPolicy: IfNotPresent
        envFrom:
          - configMapRef:
              name: otac-configmap
          - configMapRef:
              name: otac-tnsnames-configmap
              optional: true
          - configMapRef:
              name: otac-gcsserviceaccount-configmap
              optional: true
          - configMapRef:
              name: otac-otkmcert-configmap
              optional: true
        env:
        - name: OTAC_PORT
          value: "8080"
        - name: RMDIR_SLEEP_TIME
          value: "50"
        - name: RMDIR_RETRY_COUNT
          value: "2"
        readinessProbe:
            exec:
              command:
                - "/opt/opentext/shell_scripts/check_as_readiness.sh"
            initialDelaySeconds: 120
            timeoutSeconds: 5
            periodSeconds: 10
        livenessProbe:
            exec:
              command:
                - "/opt/opentext/shell_scripts/check_as_liveness.sh"
            initialDelaySeconds: 60
            timeoutSeconds: 60
            periodSeconds: 10
            failureThreshold: 5
        ports:
        - containerPort: 4034
        - containerPort: 8080
        volumeMounts:
        - mountPath: /opt/opentext/ac_bdv
          name: otac-bdv
        - mountPath: /opt/opentext/ac_dv
          name: otac-dv
        - mountPath: /opt/opentext/ac_sd
          name: otac-sd
        - mountPath: /opt/opentext/logs
          name: otac-logs
        - mountPath: /opt/opentext/archive_center/ac_config
          name: otac-config
        - mountPath: /opt/oracle/tnsnames.ora
          name: otac-tnsnames-configmap
          subPath: tnsnames.ora
        - name: otac-tomcatfiles-configmap
          mountPath: /opt/opentext/archive_center/ac_config/tomcat
        securityContext:
          allowPrivilegeEscalation: false
      volumes:
        - name: otac-config
          persistentVolumeClaim:
            claimName: otac-config
        - name: otac-tnsnames-configmap
          configMap:
            name: otac-tnsnames-configmap
        - name: otac-tomcatfiles-configmap
          configMap:
            name: otac-tomcatfiles-configmap

      hostname: otac
      imagePullSecrets:
      - name: regcred
  volumeClaimTemplates:
  - metadata:
      name: otac-bdv
      labels:
        {}
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 50Gi
  - metadata:
      name: otac-dv
      labels:
        {}
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 1Gi
  - metadata:
      name: otac-sd
      labels:
        {}
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 1Gi
  - metadata:
      name: otac-logs
      labels:
        {}
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 4Gi
---
# Source: otxecm/charts/otcs/templates/otcs-statefulsets.yaml
# Admin Server

kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: otcs-admin
  labels:
    app.kubernetes.io/component: otcs-admin
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: otcs-admin
  replicas: 
  podManagementPolicy: "OrderedReady"
  selector:
    matchLabels:
      app.kubernetes.io/component: otcs-admin
      app.kubernetes.io/instance: xecm-release
  template:
    metadata:
      labels:
        app.kubernetes.io/component: otcs-admin
        app.kubernetes.io/instance: xecm-release
    spec:
      priorityClassName: xecm-release-default-1
      securityContext:
        # Since fsGroup is specified, all processes of the container are also part of the
        # supplementary group ID. The owner for volumes and any files created in the volume will
        # be Group ID 1000, which is otuser.
        fsGroup: 1000
        runAsUser: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otxecm-sa
      terminationGracePeriodSeconds: 60
      initContainers:
      containers:
      - name: otcs-admin-container
        image: registry.opentext.com/otxecm:25.3.0
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'until [ "$(curl -s -w ''%{http_code}'' -o /dev/null http://localhost:8000/readyz)" -eq 200 ]; do echo "Waiting for Kubernetes API to be ready"; sleep 10; done; /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf']
        env:
        - name: OTCS_BACKEND_SEARCH_REPLICAS
          value: "1"
        - name: OTCS_FRONTEND_REPLICAS
          value: "1"
        - name: OTCS_TYPE
          value: primary
        - name: OTCS_CONTAINER_LOG_LEVEL
          value: DEBUG
        - name: OTCS_ROLE
          value: admin
        - name: OTDS_SERVICE_NAME
          value: "otds"
        - name: SHARED_ADDRESS_SPACE_NAT
          value: "false"
        - name: TZ
          value: Asia/Seoul
        - name: PGHOST
          value: "192.168.100.216"
        - name: PGPORT
          value: "5432"
        - name: PGUSER
          value: "postgres"
        - name: PGDATABASE
          value: "postgres"
        - name: MAX_THREAD_LIFESPAN
          value: "10"
        - name: OTXECM_SECRET_NAME
          value: otxecm-default-secrets
        - name: UALEnabled
          value: "false"
        - name: RESTART_AUTOMATION_TIME
          value: "60"
        readinessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_readiness.sh"
            initialDelaySeconds: 0
            timeoutSeconds: 6
            periodSeconds: 10
        livenessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_liveness.sh"
            initialDelaySeconds: 600
            timeoutSeconds: 15
            periodSeconds: 30
            failureThreshold: 3
        ports:
        # Content Server ports:
        - containerPort: 2099
        # admin-server
        - containerPort: 5858
        # Tomcat port:
        - containerPort: 8080
        volumeMounts:
        - mountPath: "/opt/opentext/extensions"
          name: extensions-volume-mount
        - mountPath: "/opt/opentext/cs_persist"
          name: cs-persist
        - mountPath: "/opt/opentext/multifile"
          name: otcs-multifile
        - mountPath: "/opt/opentext/cs/logs"
          name: logs
        - mountPath: "/opt/opentext/sftp"
          name: sftp-volume
        - mountPath: "/opt/opentext/container_files/custom_config/config.yaml"
          name: config
          subPath: config.yaml
        - mountPath: "/opt/opentext/cs_index"
          name: otcs-admin-index
        - mountPath: "/opt/opentext/container_files/custom_config/sp.pem"
          name: otcs-archive-cert-configmap
          subPath: sp.pem
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
      - name: kubectl-proxy
        image: docker.io/bitnami/kubectl:1.30.4
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c']
        args:
        - |
          kubectl proxy --port=8000 --address=127.0.0.1 &
          kubectl proxy --port=8000 --address=[::1] &
          wait
        ports:
            - containerPort: 8000
      volumes:
        - name: extensions-volume-mount
          emptyDir: {}
        - name: config
          configMap:
            name: otcs-admin-configmap
        # Used for Archive Center certificate file:
        - name: otcs-archive-cert-configmap
          configMap:
            name: otcs-archive-cert-configmap
        - name: sftp-volume
          persistentVolumeClaim:
            claimName: sftp-volume
        - name: otcs-multifile
          emptyDir:
            sizeLimit: 10Gi
      imagePullSecrets:
      - name: regcred
  volumeClaimTemplates:
  - metadata:
      name: cs-persist
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 6Gi
  - metadata:
      name: logs
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 5Gi
  - metadata:
      name: otcs-admin-index
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 1Gi
---
# Source: otxecm/charts/otcs/templates/otcs-statefulsets.yaml
# Distributed Agents

kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: otcs-da
  labels:
    app.kubernetes.io/component: otcs-da
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: otcs-da
  replicas: 1
  podManagementPolicy: "Parallel"
  selector:
    matchLabels:
      app.kubernetes.io/component: otcs-da
      app.kubernetes.io/instance: xecm-release
  template:
    metadata:
      labels:
        app.kubernetes.io/component: otcs-da
        app.kubernetes.io/instance: xecm-release
    spec:
      priorityClassName: xecm-release-default-2
      securityContext:
        # Since fsGroup is specified, all processes of the container are also part of the
        # supplementary group ID. The owner for volumes and any files created in the volume will
        # be Group ID 1000, which is otuser.
        fsGroup: 1000
        runAsUser: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otxecm-sa
      terminationGracePeriodSeconds: 60
      initContainers:
      containers:
      - name: otcs-da-container
        image: registry.opentext.com/otxecm:25.3.0
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'until [ "$(curl -s -w ''%{http_code}'' -o /dev/null http://localhost:8000/readyz)" -eq 200 ]; do echo "Waiting for Kubernetes API to be ready"; sleep 10; done; /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf']
        env:
        - name: OTCS_BACKEND_SEARCH_REPLICAS
          value: "1"
        - name: OTCS_FRONTEND_REPLICAS
          value: "1"
        - name: OTCS_TYPE
          value: secondary
        - name: OTCS_CONTAINER_LOG_LEVEL
          value: DEBUG
        - name: OTCS_ROLE
          value: da
        - name: OTDS_SERVICE_NAME
          value: "otds"
        - name: SHARED_ADDRESS_SPACE_NAT
          value: "false"
        - name: TZ
          value: Asia/Seoul
        - name: PGHOST
          value: "192.168.100.216"
        - name: PGPORT
          value: "5432"
        - name: PGUSER
          value: "postgres"
        - name: PGDATABASE
          value: "postgres"
        - name: MAX_THREAD_LIFESPAN
          value: "10"
        - name: OTXECM_SECRET_NAME
          value: otxecm-default-secrets
        - name: UALEnabled
          value: "false"
        - name: RESTART_AUTOMATION_TIME
          value: "60"
        readinessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_readiness.sh"
            initialDelaySeconds: 0
            timeoutSeconds: 6
            periodSeconds: 10
        livenessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_liveness.sh"
            initialDelaySeconds: 600
            timeoutSeconds: 15
            periodSeconds: 30
            failureThreshold: 3
        ports:
        # Content Server ports:
        - containerPort: 2099
        # Tomcat port:
        - containerPort: 8080
        volumeMounts:
        - mountPath: "/opt/opentext/extensions"
          name: extensions-volume-mount
        - mountPath: "/opt/opentext/cs_persist"
          name: cs-persist
        - mountPath: "/opt/opentext/multifile"
          name: otcs-multifile
        - mountPath: "/opt/opentext/cs/logs"
          name: logs
        - mountPath: "/opt/opentext/sftp"
          name: sftp-volume
        - mountPath: "/opt/opentext/container_files/custom_config/config.yaml"
          name: config
          subPath: config.yaml
        - mountPath: "/opt/opentext/container_files/custom_config/sp.pem"
          name: otcs-archive-cert-configmap
          subPath: sp.pem
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
      - name: kubectl-proxy
        image: docker.io/bitnami/kubectl:1.30.4
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c']
        args:
        - |
          kubectl proxy --port=8000 --address=127.0.0.1 &
          kubectl proxy --port=8000 --address=[::1] &
          wait
        ports:
            - containerPort: 8000
      volumes:
        - name: extensions-volume-mount
          emptyDir: {}
        - name: config
          configMap:
            name: otcs-da-configmap
        # Used for Archive Center certificate file:
        - name: otcs-archive-cert-configmap
          configMap:
            name: otcs-archive-cert-configmap
        - name: sftp-volume
          persistentVolumeClaim:
            claimName: sftp-volume
        - name: otcs-multifile
          emptyDir:
            sizeLimit: 10Gi
      imagePullSecrets:
      - name: regcred
  volumeClaimTemplates:
  - metadata:
      name: cs-persist
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 6Gi
  - metadata:
      name: logs
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 5Gi
---
# Source: otxecm/charts/otcs/templates/otcs-statefulsets.yaml
# Frontend Server

kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: otcs-frontend
  labels:
    app.kubernetes.io/component: otcs-frontend
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: otcs-frontend
  replicas: 1
  podManagementPolicy: "Parallel"
  selector:
    matchLabels:
      app.kubernetes.io/component: otcs-frontend
      app.kubernetes.io/instance: xecm-release
  template:
    metadata:
      labels:
        app.kubernetes.io/component: otcs-frontend
        app.kubernetes.io/instance: xecm-release
    spec:
      priorityClassName: xecm-release-default-2
      securityContext:
        # Since fsGroup is specified, all processes of the container are also part of the
        # supplementary group ID. The owner for volumes and any files created in the volume will
        # be Group ID 1000, which is otuser.
        fsGroup: 1000
        runAsUser: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otxecm-sa
      terminationGracePeriodSeconds: 60
      initContainers:
      containers:
      - name: otcs-frontend-container
        image: registry.opentext.com/otxecm:25.3.0
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'until [ "$(curl -s -w ''%{http_code}'' -o /dev/null http://localhost:8000/readyz)" -eq 200 ]; do echo "Waiting for Kubernetes API to be ready"; sleep 10; done; /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf']
        env:
        - name: OTCS_BACKEND_SEARCH_REPLICAS
          value: "1"
        - name: OTCS_FRONTEND_REPLICAS
          value: "1"
        - name: OTCS_TYPE
          value: secondary
        - name: OTCS_CONTAINER_LOG_LEVEL
          value: DEBUG
        - name: OTCS_ROLE
          value: frontend
        - name: OTDS_SERVICE_NAME
          value: "otds"
        - name: SHARED_ADDRESS_SPACE_NAT
          value: "false"
        - name: TZ
          value: Asia/Seoul
        - name: PGHOST
          value: "192.168.100.216"
        - name: PGPORT
          value: "5432"
        - name: PGUSER
          value: "postgres"
        - name: PGDATABASE
          value: "postgres"
        - name: MAX_THREAD_LIFESPAN
          value: "10"
        - name: OTXECM_SECRET_NAME
          value: otxecm-default-secrets
        - name: UALEnabled
          value: "false"
        - name: RESTART_AUTOMATION_TIME
          value: "60"
        readinessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_readiness.sh"
            initialDelaySeconds: 0
            timeoutSeconds: 6
            periodSeconds: 10
        livenessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_liveness.sh"
            initialDelaySeconds: 600
            timeoutSeconds: 15
            periodSeconds: 30
            failureThreshold: 3
        ports:
        # Content Server ports:
        - containerPort: 2099
        # Tomcat port:
        - containerPort: 8080
        volumeMounts:
        - mountPath: "/opt/opentext/extensions"
          name: extensions-volume-mount
        - mountPath: "/opt/opentext/cs_persist"
          name: cs-persist
        - mountPath: "/opt/opentext/multifile"
          name: otcs-multifile
        - mountPath: "/opt/opentext/cs/logs"
          name: logs
        - mountPath: "/opt/opentext/sftp"
          name: sftp-volume
        - mountPath: "/opt/opentext/container_files/custom_config/config.yaml"
          name: config
          subPath: config.yaml
        - mountPath: "/opt/opentext/container_files/custom_config/sp.pem"
          name: otcs-archive-cert-configmap
          subPath: sp.pem
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
      - name: kubectl-proxy
        image: docker.io/bitnami/kubectl:1.30.4
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c']
        args:
        - |
          kubectl proxy --port=8000 --address=127.0.0.1 &
          kubectl proxy --port=8000 --address=[::1] &
          wait
        ports:
            - containerPort: 8000
      volumes:
        - name: extensions-volume-mount
          emptyDir: {}
        - name: config
          configMap:
            name: otcs-frontend-configmap
        # Used for Archive Center certificate file:
        - name: otcs-archive-cert-configmap
          configMap:
            name: otcs-archive-cert-configmap
        - name: sftp-volume
          persistentVolumeClaim:
            claimName: sftp-volume
        - name: otcs-multifile
          emptyDir:
            sizeLimit: 10Gi
      imagePullSecrets:
      - name: regcred
  volumeClaimTemplates:
  - metadata:
      name: cs-persist
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 6Gi
  - metadata:
      name: logs
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 5Gi
---
# Source: otxecm/charts/otcs/templates/otcs-statefulsets.yaml
# Backend Search

kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: otcs-backend-search
  labels:
    app.kubernetes.io/component: otcs-backend-search
    app.kubernetes.io/name: otcs
    helm.sh/chart: otcs-25.3.0
    app.kubernetes.io/instance: xecm-release
    app.kubernetes.io/version: "25.3.0"
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: otcs-backend-search
  replicas: 1
  podManagementPolicy: "Parallel"
  selector:
    matchLabels:
      app.kubernetes.io/component: otcs-backend-search
      app.kubernetes.io/instance: xecm-release
  template:
    metadata:
      labels:
        app.kubernetes.io/component: otcs-backend-search
        app.kubernetes.io/instance: xecm-release
    spec:
      priorityClassName: xecm-release-default-2
      securityContext:
        # Since fsGroup is specified, all processes of the container are also part of the
        # supplementary group ID. The owner for volumes and any files created in the volume will
        # be Group ID 1000, which is otuser.
        fsGroup: 1000
        runAsUser: 1000
        fsGroupChangePolicy: "OnRootMismatch"
      ## serviceAccountName defines the name of the service account the
      ## pods are running under. Normally that is 'default'
      serviceAccountName: otxecm-sa
      terminationGracePeriodSeconds: 60
      initContainers:
      containers:
      - name: otcs-backend-search-container
        image: registry.opentext.com/otxecm:25.3.0
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'until [ "$(curl -s -w ''%{http_code}'' -o /dev/null http://localhost:8000/readyz)" -eq 200 ]; do echo "Waiting for Kubernetes API to be ready"; sleep 10; done; /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf']
        env:
        - name: OTCS_BACKEND_SEARCH_REPLICAS
          value: "1"
        - name: OTCS_FRONTEND_REPLICAS
          value: "1"
        - name: OTCS_TYPE
          value: secondary
        - name: OTCS_CONTAINER_LOG_LEVEL
          value: DEBUG
        - name: OTCS_ROLE
          value: backend-search
        - name: OTDS_SERVICE_NAME
          value: "otds"
        - name: SHARED_ADDRESS_SPACE_NAT
          value: "false"
        - name: TZ
          value: Asia/Seoul
        - name: PGHOST
          value: "192.168.100.216"
        - name: PGPORT
          value: "5432"
        - name: PGUSER
          value: "postgres"
        - name: PGDATABASE
          value: "postgres"
        - name: MAX_THREAD_LIFESPAN
          value: "10"
        - name: OTXECM_SECRET_NAME
          value: otxecm-default-secrets
        - name: UALEnabled
          value: "false"
        - name: RESTART_AUTOMATION_TIME
          value: "60"
        readinessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_readiness.sh"
            initialDelaySeconds: 0
            timeoutSeconds: 6
            periodSeconds: 10
        livenessProbe:
            exec:
              command:
                - "/opt/opentext/container_files/bash/check_cs_liveness.sh"
            initialDelaySeconds: 600
            timeoutSeconds: 15
            periodSeconds: 30
            failureThreshold: 3
        ports:
        # Content Server ports:
        - containerPort: 2099
        # admin-server
        - containerPort: 5858
        # Tomcat port:
        - containerPort: 8080
        volumeMounts:
        - mountPath: "/opt/opentext/extensions"
          name: extensions-volume-mount
        - mountPath: "/opt/opentext/cs_persist"
          name: cs-persist
        - mountPath: "/opt/opentext/multifile"
          name: otcs-multifile
        - mountPath: "/opt/opentext/cs/logs"
          name: logs
        - mountPath: "/opt/opentext/sftp"
          name: sftp-volume
        - mountPath: "/opt/opentext/container_files/custom_config/config.yaml"
          name: config
          subPath: config.yaml
        - mountPath: "/opt/opentext/cs_index"
          name: otcs-admin-index
        - mountPath: "/opt/opentext/container_files/custom_config/sp.pem"
          name: otcs-archive-cert-configmap
          subPath: sp.pem
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
      - name: kubectl-proxy
        image: docker.io/bitnami/kubectl:1.30.4
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c']
        args:
        - |
          kubectl proxy --port=8000 --address=127.0.0.1 &
          kubectl proxy --port=8000 --address=[::1] &
          wait
        ports:
            - containerPort: 8000
      volumes:
        - name: extensions-volume-mount
          emptyDir: {}
        - name: config
          configMap:
            name: otcs-backend-search-configmap
        # Used for Archive Center certificate file:
        - name: otcs-archive-cert-configmap
          configMap:
            name: otcs-archive-cert-configmap
        - name: sftp-volume
          persistentVolumeClaim:
            claimName: sftp-volume
        - name: otcs-multifile
          emptyDir:
            sizeLimit: 10Gi
      imagePullSecrets:
      - name: regcred
  volumeClaimTemplates:
  - metadata:
      name: cs-persist
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 6Gi
  - metadata:
      name: logs
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 5Gi
  - metadata:
      name: otcs-admin-index
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 1Gi
---
# Source: otxecm/charts/otiv/charts/amqp/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: otiv-amqp
  labels:
    name: otiv-amqp
spec:
  serviceName: otiv-amqp
  replicas: 1
  selector:
    matchLabels:
      app: otiv-amqp
      release: "xecm-release"
  template:
    metadata:
      labels:
        app: otiv-amqp
        release: "xecm-release"
        chart: rabbitmq-1
    spec:
      imagePullSecrets:
      - name: regcred
      serviceAccountName: otxecm-sa
      containers:
      - name: otiv-amqp
        image: registry.opentext.com/otiv-amqp:25.3.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          runAsUser: 1000
        ports:
        - containerPort: 15672
          name: discovery
        - containerPort: 15692
          name: metrics
        - containerPort: 5672
          name: amqp
        command:
         - /bin/bash
         - -c
         - |
            cp /tmp/config/rabbitmq.conf /config/rabbitmq.conf
            cp /tmp/config/advanced.config /config/advanced.config
            #cp /tmp/config/definitions.json /config/definitions.json
            cp /tmp/config/enabled_plugins /etc/rabbitmq/enabled_plugins
            sleep 8
            export IV_AMQP_USER=user
            max_attempts=4
            for attempt in $(seq 1 $max_attempts); do
              if IV_AMQP=$(python /tmp/ivAmqp.py); then
                export IV_AMQP
                break
              else
                if [ $attempt -lt $max_attempts ]; then
                  echo "WARNING: Failed to retrieve amqp credentials, sleeping for 5 seconds"
                  sleep 5
                else
                  echo "ERROR: Failed to retrieve amqp credentials, EXITING"
                  exit 1
                fi
              fi
            done
            rm -f /tmp/ivAmqp.py
            if [ -d "/mnt/data/var/lib/rabbitmq/mnesia/${RABBITMQ_NODENAME}" ]; then rabbitmqctl force_boot; fi
            exec rabbitmq-server
        envFrom:
        - configMapRef:
            name: otiv-configmap
        env:
        - name: AJIRA_PWD_KEY
          value: rabbitmq-password
        - name: RABBIT_POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: RABBIT_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: RABBITMQ_NODENAME
          value: rabbit@$(RABBIT_POD_NAME).otiv-amqp.$(RABBIT_POD_NAMESPACE).svc.cluster.local
        - name: K8S_HOSTNAME_SUFFIX
          value: .otiv-amqp.$(RABBIT_POD_NAMESPACE).svc.cluster.local
        - name: K8S_SERVICE_NAME
          value: "otiv-amqp"
        - name: RABBITMQ_USE_LONGNAME
          value: "true"
        - name: RABBITMQ_CONFIG_FILE
          value: "/config/rabbitmq.conf"
        - name: RABBITMQ_ADVANCED_CONFIG_FILE
          value: "/config/advanced.config"
        - name: RABBITMQ_ERLANG_COOKIE
          valueFrom:
            secretKeyRef:
              name: otiv-amqp
              key: RABBITMQ_ERLANG_COOKIE
        volumeMounts:
        - name: config
          mountPath: /tmp/config/
          readOnly: false
        - name: data
          mountPath: "/mnt/data/var/lib/rabbitmq"
          readOnly: false
        - name: config-file
          mountPath: /config/
        - name: plugins-file
          mountPath: /etc/rabbitmq/
      volumes:
      - name: config-file
        emptyDir: {}
      - name: plugins-file
        emptyDir: {}
      - name: config
        configMap:
          name: otiv-amqp-config
          defaultMode: 0755
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: "1Gi"
      storageClassName: microk8s-hostpath
---
# Source: otxecm/charts/otiv/templates/cs-vat-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: otiv-cs-vat-job
  labels:
    app.kubernetes.io/name: otiv
    helm.sh/chart: otiv-25.3.0-otxecm
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 1
  template:
    metadata:
      name: otiv-cs-vat-job
      labels:
        app.kubernetes.io/name: otiv
        helm.sh/chart: otiv-25.3.0-otxecm
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      restartPolicy: Never
      serviceAccountName: otxecm-sa
      imagePullSecrets:
      - name: regcred
      containers:
        - name: update-cs-vat-settings
          image: registry.opentext.com/otiv-config:25.3.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
          envFrom:
          - configMapRef:
              name: otiv-configmap
          env:
            - name: PUBLICATION_URL
              value: http://otiv-publication
            - name: VIEWER_URL
              value: http://otiv-viewer
            - name: HIGHLIGHT_URL
              value: http://otiv-highlight
            - name: MARKUP_URL
              value: http://otiv-markup
            - name: ASSET_URL
              value: http://otiv-asset
            - name: IV_INGRESS_SUFFIX
              value: .myubuntu6.hv
            - name: IV_WEB_PROTOCOL
              value: https
            - name: TZ
              value: 'Asia/Seoul'
          command:
            - sh
            - -c
            - |
              sleep 15;
              python ./scripts/csIvAuth.py;
---
# Source: otxecm/templates/otxecm-ingress.yaml
########################################################################
# Kubernetes Ingress for Content Server, Archive Center and OTDS
# External Interface to provide a Fully Qualified Domain Name (FQDN)
# and enable secure HTTPS communication (if global.ingressSSLSecret is provided)
########################################################################
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: otxecm-ingress
  annotations:
# Checking that K8s version is 1.17 or earlier
    alb.ingress.kubernetes.io/configuration-snippet: 'if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
'
    alb.ingress.kubernetes.io/load-balancer-attributes: 'idle_timeout.timeout_seconds=1800'
    alb.ingress.kubernetes.io/scheme: 'internet-facing'
    alb.ingress.kubernetes.io/target-group-attributes: 'stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=30'
    alb.ingress.kubernetes.io/target-type: 'ip'
    kubernetes.io/ingress.allow-http: 'false'
    nginx.ingress.kubernetes.io/affinity: 'cookie'
    nginx.ingress.kubernetes.io/configuration-snippet: 'if ($http_origin) {more_set_headers "Access-Control-Allow-Headers: $sent_http_access_control_allow_headers, X-XHR-Logon, X-Requested-With";}
'
    nginx.ingress.kubernetes.io/proxy-body-size: '0'
    nginx.ingress.kubernetes.io/proxy-buffer-size: '16k'
    nginx.ingress.kubernetes.io/proxy-read-timeout: '1800'
    nginx.ingress.kubernetes.io/proxy-send-timeout: '600'
    nginx.ingress.kubernetes.io/server-snippet: 'add_header X-Robots-Tag "noindex, nofollow";'
spec:
# Checking that K8s version is 1.18 or greater
  ingressClassName: nginx
  tls:
    - hosts:
      - otcs.myubuntu6.hv
      - otds.myubuntu6.hv
      - otac.myubuntu6.hv
      - otiv-asset.myubuntu6.hv
      - otiv-highlight.myubuntu6.hv
      - otiv-markup.myubuntu6.hv
      - otiv-publication.myubuntu6.hv
      - otiv-viewer.myubuntu6.hv
      secretName: xecm-secret
  rules:
  - host: otcs.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otcs-frontend
            port:
              number: 80
        path: /
        pathType: Prefix
  - host: otds.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: "otds"
            port:
              number: 80
        path: /
        pathType: Prefix
  - host: otac.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otac-0
            port:
              number: 8080
        path: /
        pathType: Prefix
  - host: otiv-asset.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otiv-asset
            port:
              name: http
        path: /
        pathType: Prefix
  - host: otiv-highlight.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otiv-highlight
            port:
              name: http
        path: /
        pathType: Prefix
  - host: otiv-markup.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otiv-markup
            port:
              name: http
        path: /
        pathType: Prefix
  - host: otiv-publication.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otiv-publication
            port:
              name: http
        path: /
        pathType: Prefix
  - host: otiv-viewer.myubuntu6.hv
    http:
      paths:
      - backend:
          service:
            name: otiv-viewer
            port:
              name: http
        path: /
        pathType: Prefix
---
# Source: otxecm/charts/otac/templates/otac-configmaps.yaml
########################################################################
# db custom certificate files ##UPDATE
########################################################################
########################################################################
# gcs custom certificate files ##UPDATE
########################################################################
########################################################################
# s3 custom certificate files ##UPDATE
########################################################################
########################################################################
# azure custom certificate files ##UPDATE
########################################################################
########################################################################
# gcs_serviceaccount.json ##UPDATE
########################################################################
########################################################################
# OTKM Root CA Path ##UPDATE
########################################################################
---
# Source: otxecm/charts/otac/templates/otac-pre-upgrade.yaml
# Pre-upgrade cleanup job definition for OTAC Container
---
# Source: otxecm/templates/error-checking.tpl
# Validation for license secret

    # Validation for otac certificate secret

    # Validation for otacc certificate secret
    
    # Validation for UAL certificate secret

    # Validation for pre-existing adminsettings configmaps









# Ensure PowerDocs charts has the correct values.

NOTES:
Thank you for installing otxecm

Your release is named xecm-release
The release revision is 1

To learn more about the release, try:

  $ helm status xecm-release
  $ helm get all xecm-release

To see all deployed releases type:

  $ helm list -a

To see the status of the Kubernetes pods, try:

  $ kubectl get pods -w

To finally delete the deployment and its persistent storage, try:

  $ helm delete xecm-release
  $ kubectl delete pvc --all
